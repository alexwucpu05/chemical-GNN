{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chem_rdkit_GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXYcPnw5SAfJxbRVK0F7pB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexwucpu05/chemical-GNN/blob/main/chem_rdkit_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "iUdFg5uG25ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## rdkit"
      ],
      "metadata": {
        "id": "PPxjXxbjL5Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install RDKit. Takes 2-3 minutes\n",
        "# !wget -c https://repo.anaconda.com/miniconda/Miniconda3-py37_4.11.0-Linux-x86_64.sh\n",
        "# !chmod +x Miniconda3-py37_4.11.0-Linux-x86_64.sh\n",
        "# !time bash ./Miniconda3-py37_4.11.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "# !time conda install -q -y -c conda-forge rdkit==2020.09.2"
      ],
      "metadata": {
        "id": "R4iuWdff28w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # append rdkit path to current python system path\n",
        "# import sys\n",
        "# import os\n",
        "# sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "metadata": {
        "id": "5OKj9gawpqnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vs3kG6SseDf",
        "outputId": "4ab832ab-12f6-4c46-be61-3fd657b52952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:29\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y7l4PEwsno-",
        "outputId": "5d4ab122-1b74-4560-94c4-eabf2e45d266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -q -y -c conda-forge rdkit"
      ],
      "metadata": {
        "id": "kv-GgST5sb0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pytorch"
      ],
      "metadata": {
        "id": "Twmms4KgL7Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "!python --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLVC0JPrPPkh",
        "outputId": "fd17919a-46f4-4d68-f35f-3ff38fd6ff43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "11.1\n",
            "Python 3.7.12\n",
            "Tue Mar 22 21:44:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Enforce pytorch version 1.6.0\n",
        "# import torch\n",
        "# if torch.__version__ != '1.6.0':\n",
        "#   !pip uninstall torch -y\n",
        "#   !pip uninstall torchvision -y\n",
        "#   !pip install torch==1.6.0\n",
        "#   !pip install torchvision==0.7.0\n",
        "\n",
        "# # Check pytorch version and make sure you use a GPU Kernel\n",
        "# !python -c \"import torch; print(torch.__version__)\"\n",
        "# !python -c \"import torch; print(torch.version.cuda)\"\n",
        "# !python --version\n",
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "eL9w79J5MA8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Enforce pytorch version 1.8.0\n",
        "# !pip uninstall torch -y\n",
        "# !pip uninstall torchvision -y\n",
        "# !pip uninstall torchaudio -y\n",
        "# !pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "LkZT4OaPO_C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pytorch geometric"
      ],
      "metadata": {
        "id": "KNjRRauPMBaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If something breaks in the notebook it is probably related to a mismatch between the Python version, CUDA or torch\n",
        "import torch\n",
        "pytorch_version = f\"torch-{torch.__version__}.html\"\n",
        "print(f\"pytorch_version: {pytorch_version}\")\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/$pytorch_version\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/$pytorch_version\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/$pytorch_version\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/$pytorch_version\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbYJrwAAL_1q",
        "outputId": "21dbf71f-f3be-49b4-edba-a90c86a7a4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch_version: torch-1.10.0+cu111.html\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.9 MB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.5 MB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.5 MB 2.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750 kB 2.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 407 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=6fed5682a557c4cda066c78d6e111be1a3d1a3f82852c8febf0f850401d516a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pytorch lightning"
      ],
      "metadata": {
        "id": "u2j5EBdjQSyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Lightning\n",
        "!pip install pytorch-lightning==1.3.4 -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M12bmKxQWpt",
        "outputId": "7a229e18-7e69-4fcb-8fa7-cb79b5632843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 806 kB 5.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134 kB 46.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 397 kB 42.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 40.7 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 829 kB 52.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 39.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271 kB 51.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94 kB 3.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 47.9 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics -q"
      ],
      "metadata": {
        "id": "INuUSAfZt_EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load libraries"
      ],
      "metadata": {
        "id": "SLlr7tv_29O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from joblib import load, dump\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F \n",
        "# from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "uj8dM5iZ3Vjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RDkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem.rdmolops import GetAdjacencyMatrix"
      ],
      "metadata": {
        "id": "tGcGaVpw28sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pyG\n",
        "from torch_geometric import nn as geom_nn\n",
        "from torch_geometric import datasets as geom_datasets\n",
        "from torch_geometric.nn import GCNConv, GraphConv, TopKPooling, global_mean_pool, global_max_pool\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader"
      ],
      "metadata": {
        "id": "sCQS0mka28oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "import torchmetrics"
      ],
      "metadata": {
        "id": "HTLpWlzU6bbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "_Iizbbef2_hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to_2hKzw28lw",
        "outputId": "d8eaa625-e503-4eeb-f968-e67241db2584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set env var"
      ],
      "metadata": {
        "id": "vt91UFU93DVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/DILI_models/GNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpc6Un5pNpE6",
        "outputId": "acf8df5e-9dc1-4201-cfb2-033abbfd1e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# root_dir = Path('.')\n",
        "\n",
        "root_dir = Path('/content/drive/MyDrive/DILI_models/GNN')\n",
        "data_dir = root_dir/Path('data')\n",
        "log_dir = root_dir/Path('logs')"
      ],
      "metadata": {
        "id": "fY3sABDX28jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4HYuobSQ28gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "aswLnEDTVZbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DILIrank Most/No DILI concern drugs (Deep Graph Learning paper)"
      ],
      "metadata": {
        "id": "hA02QlsxVc0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.read_excel(data_dir/Path(\"DILIrank_most_no_DeepGraph.xlsx\"))\n",
        "df_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MJPPfO7cVcfe",
        "outputId": "2b537e35-fd53-4bb5-9e68-570ed41f95a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               smile  dili\n",
              "0                     CNCC[C@@H](Oc1ccccc1C)c2ccccc2     1\n",
              "1      CN1CCC[C@@H]1CCO[C@](C)(c2ccccc2)c3ccc(Cl)cc3     0\n",
              "2                  CN(C)CCCN1c2ccccc2CCc3ccc(Cl)cc13     1\n",
              "3              CN1CCN(CC1)C2=Nc3cc(Cl)ccc3Nc4ccccc24     1\n",
              "4  NC(=O)C([C@@H]1CCN(CCc2ccc3OCCc3c2)C1)(c4ccccc...     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a8ccf35-fdb0-4eed-9232-1c13084dec38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smile</th>\n",
              "      <th>dili</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNCC[C@@H](Oc1ccccc1C)c2ccccc2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CN1CCC[C@@H]1CCO[C@](C)(c2ccccc2)c3ccc(Cl)cc3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CN(C)CCCN1c2ccccc2CCc3ccc(Cl)cc13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CN1CCN(CC1)C2=Nc3cc(Cl)ccc3Nc4ccccc24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NC(=O)C([C@@H]1CCN(CCc2ccc3OCCc3c2)C1)(c4ccccc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a8ccf35-fdb0-4eed-9232-1c13084dec38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a8ccf35-fdb0-4eed-9232-1c13084dec38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a8ccf35-fdb0-4eed-9232-1c13084dec38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"DILI positive drugs: {len(df_data[df_data.dili == 1])}\")\n",
        "print(f\"DILI negative drugs: {len(df_data[df_data.dili == 0])}\")\n",
        "print(f\"total drugs: {len(df_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an1AjgGCVcag",
        "outputId": "506c21e8-12c5-45a5-aa87-754474c4b72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DILI positive drugs: 197\n",
            "DILI negative drugs: 282\n",
            "total drugs: 479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIList (DeepDILI paper)"
      ],
      "metadata": {
        "id": "IcfHipu3V4N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pPWoxTfqVcWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate graphs, node/edge features using rdkit"
      ],
      "metadata": {
        "id": "4_iy6ZsuMZ3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## helper functions"
      ],
      "metadata": {
        "id": "IR8o9B6eMuNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_one_hot_encoding(query, vocab):\n",
        "    if query not in vocab:\n",
        "        query = vocab[-1] # use 'other' as the last element\n",
        "    one_hot_vec = [int(match_result) for match_result in list(map(lambda item: query == item, vocab))]\n",
        "    return one_hot_vec"
      ],
      "metadata": {
        "id": "jP9hiCkPTNEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adj_mx_to_edge_list(adj_matrix, wide=True):\n",
        "    '''\n",
        "    This takes a 2d array as input, and output an edge list (source, targe) with shape (2, n_edges).\n",
        "    '''\n",
        "    row_idx, col_idx = np.nonzero(adj_matrix)\n",
        "    row_idx = np.array(row_idx)\n",
        "    col_idx = np.array(col_idx)\n",
        "    if wide:\n",
        "        edge_list = np.stack((row_idx, col_idx), axis=0)\n",
        "    else:\n",
        "        edge_list = np.stack((row_idx, col_idx), axis=1)\n",
        "    return edge_list\n",
        "\n",
        "def edge_list_to_adj_mx(edge_list):\n",
        "    '''\n",
        "    This takes a 2d-array edge list (source, targe) as input, and output an adj_matrix.\n",
        "    '''\n",
        "    n_row, n_col = edge_list.shape\n",
        "    # wide\n",
        "    if n_row < n_col:\n",
        "        dim_adj = int(n_col/2)\n",
        "        adj_matrix = np.zeros((dim_adj, dim_adj), dtype=np.int64)\n",
        "        for k in range(n_col):\n",
        "            i = edge_list[0, k]\n",
        "            j = edge_list[1, k]\n",
        "            adj_matrix[i, j] = 1\n",
        "    else: \n",
        "        dim_adj = int(n_row/2)\n",
        "        adj_matrix = np.zeros((dim_adj, dim_adj), dtype=np.int64)\n",
        "        for i, j in edge_list:\n",
        "            adj_matrix[i, j] = 1\n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "qkPoXvd4TNAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "    'atom_type': ['Li', 'Be', 'B', 'C','N','O','F','Na','Mg','Al','Si','P','S','Cl','K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn','Ga','Ge','As','Se','Br','I','Tl','Yb','Sb','Sn','Ag','Pd','Co','Au','Cd','In','Zr','Pt','Hg','Pb','OTHER'],\n",
        "    'hybridization': [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"],\n",
        "    'chirality_type': [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"OTHER\"],\n",
        "    'num_neighbors': [0, 1, 2, 3, 4, \"MoreThanFour\"],\n",
        "    'formal_charge': [-3, -2, -1, 0, 1, 2, 3, \"OTHER\"],\n",
        "    'num_hydrogens': [0, 1, 2, 3, 4, \"MoreThanFour\"],\n",
        "    'bond_type': [\"SINGLE\", \"DOUBLE\", \"TRIPLE\", \"AROMATIC\"],\n",
        "    'stereo_type': [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"],\n",
        "}"
      ],
      "metadata": {
        "id": "fBUZyctCTM8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chemical_Graph:\n",
        "    def __init__(self, smiles, label, vocab, chirality=True, hydrogens_implicit=True, stereochemistry=True):\n",
        "        self.molecule = Chem.MolFromSmiles(smiles)\n",
        "        self.label = torch.tensor(np.array([label])).float()\n",
        "        self.vocab = vocab\n",
        "        if not hydrogens_implicit:\n",
        "            self.vocab['atom_type'] = ['H'] + self.vocab['atom_type']\n",
        "        self.chirality = chirality\n",
        "        self.hydrogens_implicit = hydrogens_implicit\n",
        "        self.stereochemistry = stereochemistry\n",
        "        # standard scalers\n",
        "        self.scalers = {\n",
        "            'atomic_mass': None,\n",
        "            'vdw_radius': None,\n",
        "            'covalent_radius': None,\n",
        "        }\n",
        "        self.create_scalers()\n",
        "        # dimensions\n",
        "        self.n_nodes = self.molecule.GetNumAtoms()\n",
        "        self.n_edges = 2*self.molecule.GetNumBonds()\n",
        "        self.n_node_features = len(self.get_atom_features(self.molecule.GetAtomWithIdx(0)))\n",
        "        self.n_egde_features = len(self.get_bond_features(self.molecule.GetBonds()[0]))\n",
        "        # get graph-level data (node/edge features, edge_index, label)\n",
        "        self.get_graph_data()\n",
        "\n",
        "\n",
        "    def train_standard_scaler(self, atom_features):\n",
        "        '''\n",
        "        input should be a 2d array\n",
        "        '''\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(atom_features)\n",
        "        return scaler\n",
        "    \n",
        "    def scaler_transform(self, scaler, data):\n",
        "        scaled_array = scaler.transform(np.array(data).reshape(-1, 1))\n",
        "        return list(scaled_array.reshape(-1))\n",
        "\n",
        "    def create_scalers(self):\n",
        "        atomic_mass = [float(atom.GetMass()) for atom in self.molecule.GetAtoms()]\n",
        "        vdw_radius = [float(Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum())) for atom in self.molecule.GetAtoms()]\n",
        "        covalent_radius = [float(Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum())) for atom in self.molecule.GetAtoms()]\n",
        "        self.scalers['atomic_mass'] = self.train_standard_scaler(atom_features=np.array(atomic_mass).reshape(-1, 1))\n",
        "        self.scalers['vdw_radius'] = self.train_standard_scaler(atom_features=np.array(vdw_radius).reshape(-1, 1))\n",
        "        self.scalers['covalent_radius'] = self.train_standard_scaler(atom_features=np.array(covalent_radius).reshape(-1, 1))\n",
        "\n",
        "    def get_atom_features(self, atom, external_atom_embedding=None):\n",
        "        '''\n",
        "        This generates lists of feature vectors for a given atom, and combines features into a single list of vector. \n",
        "        Output in np.array.\n",
        "        '''\n",
        "        if external_atom_embedding:\n",
        "            atom_type_vec = list(external_atom_embedding)\n",
        "        else:\n",
        "            atom_type_vec = create_one_hot_encoding(str(atom.GetSymbol()), self.vocab['atom_type'])\n",
        "        num_neighbors_vec = create_one_hot_encoding(int(atom.GetDegree()), self.vocab['num_neighbors'])    \n",
        "        formal_charge_vec = create_one_hot_encoding(int(atom.GetFormalCharge()), self.vocab['formal_charge'])    \n",
        "        hybridisation_type_vec = create_one_hot_encoding(str(atom.GetHybridization()), self.vocab['hybridization'])   \n",
        "        is_ring_vec = [int(atom.IsInRing())]    \n",
        "        is_aromatic_vec = [int(atom.GetIsAromatic())]\n",
        "        # use trained scaler to scale selected features\n",
        "        atomic_mass_scaled_vec = self.scaler_transform(self.scalers['atomic_mass'], atom.GetMass())\n",
        "        vdw_radius_scaled_vec = self.scaler_transform(self.scalers['vdw_radius'], Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()))\n",
        "        covalent_radius_scaled_vec = self.scaler_transform(self.scalers['covalent_radius'], Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()))\n",
        "        # combine features vectors into a single list\n",
        "        atom_features_vec = atom_type_vec + num_neighbors_vec + formal_charge_vec + hybridisation_type_vec + is_ring_vec + is_aromatic_vec + atomic_mass_scaled_vec + vdw_radius_scaled_vec + covalent_radius_scaled_vec\n",
        "\n",
        "        if self.chirality:\n",
        "            chirality_type_vec = create_one_hot_encoding(str(atom.GetChiralTag()), self.vocab['chirality_type'])\n",
        "            atom_features_vec += chirality_type_vec\n",
        "    \n",
        "        if not self.hydrogens_implicit:\n",
        "            num_hydrogens_vec = create_one_hot_encoding(int(atom.GetTotalNumHs()), self.vocab['num_hydrogens'])\n",
        "            atom_features_vec += num_hydrogens_vec\n",
        "\n",
        "        return np.array(atom_features_vec)\n",
        "\n",
        "    def get_bond_features(self, bond):\n",
        "        '''\n",
        "        This generates lists of feature vectors for a given bond, and combines features into a single list of vector. \n",
        "        Output in np.array.\n",
        "        '''\n",
        "        bond_type_vec = create_one_hot_encoding(str(bond.GetBondType()), self.vocab['bond_type'])   \n",
        "        bond_is_conjugated_vec = [int(bond.GetIsConjugated())]   \n",
        "        bond_is_ring_vec = [int(bond.IsInRing())]  \n",
        "\n",
        "        bond_features_vec = bond_type_vec + bond_is_conjugated_vec + bond_is_ring_vec\n",
        "    \n",
        "        if self.stereochemistry:\n",
        "            stereo_type_vec = create_one_hot_encoding(str(bond.GetStereo()), self.vocab['stereo_type'])\n",
        "            bond_features_vec += stereo_type_vec\n",
        "        return np.array(bond_features_vec)\n",
        "\n",
        "    def get_graph_data(self):\n",
        "        # node features (X)\n",
        "        X = np.zeros((self.n_nodes, self.n_node_features))\n",
        "        for atom in self.molecule.GetAtoms():\n",
        "            X[atom.GetIdx(), :] = self.get_atom_features(atom)\n",
        "        self.X = torch.tensor(X).float()\n",
        "        # edge index (source, target) in wide format\n",
        "        edge_index = adj_mx_to_edge_list(GetAdjacencyMatrix(self.molecule))\n",
        "        self.edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "        # edge features\n",
        "        edge_features = np.zeros((self.n_edges, self.n_egde_features))\n",
        "        for bond_idx in range(self.n_edges): # iterate along edge_index's col\n",
        "            src_idx = int(self.edge_index[0, bond_idx])\n",
        "            trg_idx = int(self.edge_index[1, bond_idx])\n",
        "            edge_features[bond_idx] = self.get_bond_features(self.molecule.GetBondBetweenAtoms(src_idx, trg_idx))\n",
        "        self.edge_attr = torch.tensor(edge_features).float()\n",
        "\n",
        "    def prepare_pyG_dataset(self):\n",
        "        return Data(x=self.X, edge_index=self.edge_index, edge_attr=self.edge_attr, y=self.label)\n",
        "         "
      ],
      "metadata": {
        "id": "vQMmbyVMTM4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(X, y, dev=True, test_size=0.2, dev_size=0.2, shuffle=True, seed=42, stratify=True):\n",
        "    if dev:\n",
        "        if stratify:\n",
        "            X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle=shuffle, stratify=y)\n",
        "            X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=dev_size, random_state=seed, shuffle=shuffle, stratify=y_train_dev)\n",
        "        else:    \n",
        "            X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle=shuffle)\n",
        "            X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=dev_size, random_state=seed, shuffle=shuffle)\n",
        "        return X_train, X_dev, X_test, y_train, y_dev, y_test\n",
        "    else:\n",
        "        if stratify:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle=shuffle, stratify=y)\n",
        "        else:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle=shuffle)\n",
        "        return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "7xB_d3sp7_qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_from_SMILES_list(smiles, labels, output_dataset=True, save_path=None):\n",
        "    data_list = []\n",
        "    for smiles_code, label in list(zip(smiles, labels)):\n",
        "        graph = Chemical_Graph(smiles_code, label, vocab)\n",
        "        if output_dataset:\n",
        "            data_list.append(graph.prepare_pyG_dataset())\n",
        "        else:\n",
        "            data_list.append({\n",
        "                \"X\": graph.X,\n",
        "                \"edge_index\": graph.edge_index,\n",
        "                \"edge_attr\": graph.edge_attr,\n",
        "                \"y\": graph.label,\n",
        "            })\n",
        "    if save_path:\n",
        "        dump(data_list, save_path)\n",
        "        print(f\"data saved to {save_path}\")\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "4Pjrw-ekW_5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(data_list):\n",
        "    dataset_list = []\n",
        "    for graph_data in data_list:\n",
        "        dataset = Data(x=graph_data['X'], edge_index=graph_data['edge_index'], edge_attr=graph_data['edge_attr'], y=graph_data['y'])\n",
        "        dataset_list.append(dataset)\n",
        "    return dataset_list"
      ],
      "metadata": {
        "id": "Qe7R1SYm28dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataloader(data, batch_size, train_ratio=0.8):\n",
        "    data_size = len(data)\n",
        "    train_size = int(data_size * train_ratio)\n",
        "    train_loader = DataLoader(data[:train_size], batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(data[train_size:], batch_size=batch_size, shuffle=True)\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "rAnG7ivT_9sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare data using rdkit and save to disk"
      ],
      "metadata": {
        "id": "vpHa0q4hM3Ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_dev, X_test, y_train, y_dev, y_test = data_split(df_data.smile.to_list(), df_data.dili.to_list())\n",
        "X_train, X_test, y_train, y_test = data_split(df_data.smile.to_list(), df_data.dili.to_list(), dev=False)\n",
        "print(f\"train: {len(X_train)}\")\n",
        "print(f\"test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-5WNPqf-4sR",
        "outputId": "5e5742bb-a502-4784-bd99-f8cc9536c265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 383\n",
            "test: 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = prepare_data_from_SMILES_list(X_train, y_train, save_path=data_dir/Path(\"DILIrank_train_data.joblib\"))\n",
        "test_dataset = prepare_data_from_SMILES_list(X_test, y_test, save_path=data_dir/Path(\"DILIrank_test_data.joblib\"))\n",
        "# dev_dataset = prepare_data_from_SMILES_list(X_train, y_train, save_path=data_dir/Path(\"DILIrank_train_data.joblib\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSRdYAny-4oA",
        "outputId": "e472e3b7-f980-4251-fb8c-c8a9518125ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data saved to /content/drive/MyDrive/DILI_models/GNN/data/DILIrank_train_data.joblib\n",
            "data saved to /content/drive/MyDrive/DILI_models/GNN/data/DILIrank_test_data.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = prepare_data_from_SMILES_list(df_data.smile.to_list(), df_data.dili.to_list(), save_path=data_dir/Path(\"DILIrank_data.joblib\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXi1bZU628Za",
        "outputId": "536c21b5-d4db-497e-e3c9-5fba5c81a1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data saved to /content/drive/MyDrive/DILI_models/GNN/data/DILIrank_data.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z_w25F_VFd1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare PyG dataset"
      ],
      "metadata": {
        "id": "rhC_ugrxM9lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = load(data_dir/Path(\"DILIrank_data.joblib\"))"
      ],
      "metadata": {
        "id": "aNFd2GT3Tlg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load(data_dir/Path(\"DILIrank_train_data.joblib\"))\n",
        "test_dataset = load(data_dir/Path(\"DILIrank_test_data.joblib\"))\n",
        "# dev_data = load(data_dir/Path(\"DILIrank_train_data.joblib\"))"
      ],
      "metadata": {
        "id": "LX_vB436ZZPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "val_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "f13Ob2BDZmmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(\"Batch:\", batch)\n",
        "print(\"Labels:\", batch.y[:10])\n",
        "print(\"Batch indices:\", batch.batch[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IRl2fxbhk2Z",
        "outputId": "23e3cdb3-bfd4-4e0f-dae2-cba2d4a9dddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: DataBatch(x=[366, 77], edge_index=[2, 782], edge_attr=[782, 10], y=[16], batch=[366], ptr=[17])\n",
            "Labels: tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
            "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(val_loader))\n",
        "print(\"Batch:\", batch)\n",
        "print(\"Labels:\", batch.y[:10])\n",
        "print(\"Batch indices:\", batch.batch[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcWslxAdiqVW",
        "outputId": "ff3321fb-7b15-4be5-c47e-bc916d6d067e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: DataBatch(x=[715, 77], edge_index=[2, 1498], edge_attr=[1498, 10], y=[16], batch=[715], ptr=[17])\n",
            "Labels: tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
            "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model config"
      ],
      "metadata": {
        "id": "Yh7W7uxZNBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNModelClassifier(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden, c_out, dropout_conv=0, dropout_linear=0.5, **kwargs):\n",
        "        super(GCNModelClassifier, self).__init__()\n",
        "\n",
        "        # GCN layers\n",
        "        self.GCNModule = nn.ModuleList([\n",
        "            # initial Conv layer\n",
        "            GCNConv(c_in, c_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_conv),\n",
        "            # 2nd Conv layer\n",
        "            GCNConv(c_hidden, c_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_conv),\n",
        "            # 3rd Conv layer\n",
        "            GCNConv(c_hidden, c_hidden),\n",
        "        ])\n",
        "\n",
        "        # classification layer\n",
        "        self.Classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_linear),\n",
        "            nn.Linear(c_hidden, c_out),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch_index):\n",
        "        # GCN layers\n",
        "        for layer in self.GCNModule:\n",
        "            # only PyG Conv layers needs edge_index\n",
        "            if isinstance(layer, geom_nn.MessagePassing):\n",
        "                x = layer(x, edge_index)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "        # Global Pooling  \n",
        "        x = global_mean_pool(x, batch_index)\n",
        "\n",
        "        # # Global Pooling (stack different aggregations) c_hidden*2\n",
        "        # x = torch.cat([global_max_pool(x, batch_index), \n",
        "        #                global_mean_pool(x, batch_index)], dim=1)\n",
        "\n",
        "        # classification\n",
        "        x = self.Classifier(x)\n",
        "        return x\n",
        "\n",
        "model = GCNModelClassifier(c_in=77, c_hidden=256, c_out=2)\n",
        "print(model)\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGkUnwomNAbF",
        "outputId": "7f74aaf7-20dc-4f11-bf86-d69eaee0f10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCNModelClassifier(\n",
            "  (GCNModule): ModuleList(\n",
            "    (0): GCNConv(77, 256)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0, inplace=False)\n",
            "    (3): GCNConv(256, 256)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0, inplace=False)\n",
            "    (6): GCNConv(256, 256)\n",
            "  )\n",
            "  (Classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=256, out_features=2, bias=True)\n",
            "    (2): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "Number of parameters:  152066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvModelClassifier(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden, c_out, dropout_conv=0, dropout_linear=0.5, **kwargs):\n",
        "        super(GraphConvModelClassifier, self).__init__()\n",
        "\n",
        "        # GraphConv layers\n",
        "        self.GraphConvModule = nn.ModuleList([\n",
        "            # initial Conv layer\n",
        "            GraphConv(c_in, c_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_conv),\n",
        "            # 2nd Conv layer\n",
        "            GraphConv(c_hidden, c_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_conv),\n",
        "            # 3rd Conv layer\n",
        "            GraphConv(c_hidden, c_hidden),\n",
        "        ])\n",
        "\n",
        "        # classification layer\n",
        "        self.Classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_linear),\n",
        "            nn.Linear(c_hidden, c_out),\n",
        "            # nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch_index):\n",
        "        # GCN layers\n",
        "        for layer in self.GraphConvModule:\n",
        "            # only PyG Conv layers needs edge_index\n",
        "            if isinstance(layer, geom_nn.MessagePassing):\n",
        "                x = layer(x, edge_index)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "        # Global Pooling  \n",
        "        x = global_mean_pool(x, batch_index)\n",
        "\n",
        "        # # Global Pooling (stack different aggregations) c_hidden*2\n",
        "        # x = torch.cat([global_max_pool(x, batch_index), \n",
        "        #                global_mean_pool(x, batch_index)], dim=1)\n",
        "\n",
        "        # classification\n",
        "        x = self.Classifier(x)\n",
        "        return x\n",
        "\n",
        "model = GraphConvModelClassifier(c_in=77, c_hidden=256, c_out=2)\n",
        "print(model)\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJvlrM_hRZ17",
        "outputId": "77ae5725-d9aa-4708-bdd1-2a4051d67fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GraphConvModelClassifier(\n",
            "  (GraphConvModule): ModuleList(\n",
            "    (0): GraphConv(77, 256)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0, inplace=False)\n",
            "    (3): GraphConv(256, 256)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0, inplace=False)\n",
            "    (6): GraphConv(256, 256)\n",
            "  )\n",
            "  (Classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=256, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters:  302850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = next(iter(train_loader))\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1BLUevxNAX1",
        "outputId": "e0d82bbe-a14e-4176-d4eb-60a79d9d3bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataBatch(x=[366, 77], edge_index=[2, 782], edge_attr=[782, 10], y=[16], batch=[366], ptr=[17])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sH00WxkgrSq",
        "outputId": "9f80aa5b-b552-48af-bfe7-486850b81b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(test.x, test.edge_index, test.batch)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LebveNJgYBJ",
        "outputId": "0ab8d7ee-a280-4562-f2b0-f3305ce6af45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4292, 0.5708],\n",
              "        [0.2267, 0.7733],\n",
              "        [0.3676, 0.6324],\n",
              "        [0.6705, 0.3295],\n",
              "        [0.5885, 0.4115],\n",
              "        [0.4923, 0.5077],\n",
              "        [0.2655, 0.7345],\n",
              "        [0.3262, 0.6738],\n",
              "        [0.3076, 0.6924],\n",
              "        [0.5426, 0.4574],\n",
              "        [0.3517, 0.6483],\n",
              "        [0.5312, 0.4688],\n",
              "        [0.4981, 0.5019],\n",
              "        [0.6321, 0.3679],\n",
              "        [0.3190, 0.6810],\n",
              "        [0.5532, 0.4468]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.argmax(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw-KSrvnkKDC",
        "outputId": "ff44c109-fa39-4aa7-dd3f-25c41e162b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC0zCtdqH32A",
        "outputId": "aa52a766-8099-4346-e371-34ec67d5d0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "q898r04zWlGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GCNModelClassifier(c_in=7, c_hidden=256, c_out=2)\n",
        "model = GraphConvModelClassifier(c_in=7, c_hidden=256, c_out=1)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXmfS2JZH-8X",
        "outputId": "f400a319-b26d-4278-c425-d37aedbedbe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphConvModelClassifier(\n",
              "  (GraphConvModule): ModuleList(\n",
              "    (0): GraphConv(7, 256)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0, inplace=False)\n",
              "    (3): GraphConv(256, 256)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0, inplace=False)\n",
              "    (6): GraphConv(256, 256)\n",
              "  )\n",
              "  (Classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=256, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)"
      ],
      "metadata": {
        "id": "rwYN1PIEI2Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xl_zSn4eWj4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    for batch in graph_train_loader:\n",
        "        inputs, edge_index, batch_idx, labels = batch.x.to(device), batch.edge_index.to(device), batch.batch.to(device), batch.y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(inputs, edge_index, batch_idx)\n",
        "        loss = criterion(logits.squeeze(dim=-1), labels.float())\n",
        "\n",
        "        preds = (logits > 0).float().detach().cpu().flatten()\n",
        "        predictions = []\n",
        "        for i in preds:\n",
        "            if i > 0:\n",
        "                predictions.append(1)\n",
        "            else:\n",
        "                predictions.append(0)\n",
        "        acc = accuracy_score(labels.detach().cpu(), predictions)\n",
        "        \n",
        "        # loss = criterion(logits, labels.type(dtype=torch.long))\n",
        "        # preds = logits.argmax(dim=1)\n",
        "        # acc = (preds == labels).sum().float() / preds.shape[0]\n",
        "        print(f\"epoch: {epoch}, train_loss: {loss.item()}, train_acc: {acc}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # evaluation\n",
        "        with torch.no_grad():\n",
        "            val_loss_accumulated = []\n",
        "            acc_accumulated = []\n",
        "            for batch in graph_test_loader:\n",
        "                inputs, edge_index, batch_idx, labels = batch.x.to(device), batch.edge_index.to(device), batch.batch.to(device), batch.y.to(device)\n",
        "                logits = model(inputs, edge_index, batch_idx)                \n",
        "                val_loss = criterion(logits.squeeze(dim=-1), labels.float()).item()\n",
        "                val_loss_accumulated.append(val_loss)\n",
        "\n",
        "                preds = (logits > 0).float().detach().cpu().flatten()\n",
        "                predictions = []\n",
        "                for i in preds:\n",
        "                    if i > 0:\n",
        "                        predictions.append(1)\n",
        "                    else:\n",
        "                        predictions.append(0)\n",
        "                acc = accuracy_score(labels.detach().cpu(), predictions)\n",
        "                # preds = logits.argmax(dim=-1)\n",
        "                # acc = (preds == labels).sum().float() / preds.shape[0]\n",
        "                acc_accumulated.append(acc)\n",
        "            val_loss_accumulated = torch.mean(torch.tensor(val_loss_accumulated))\n",
        "            acc_accumulated = torch.mean(torch.tensor(acc_accumulated))\n",
        "            print(f\"epoch: {epoch}, val_loss: {val_loss_accumulated.item()}, val_acc: {acc_accumulated}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1NKkL1rGYYg",
        "outputId": "60503eaf-70f5-414c-e0d0-523a982b45b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, train_loss: 0.7038460969924927, train_acc: 0.515625\n",
            "epoch: 0, val_loss: 14.33591365814209, val_acc: 0.6842105263157895\n",
            "epoch: 0, train_loss: 16.016258239746094, train_acc: 0.65625\n",
            "epoch: 0, val_loss: 8.125044822692871, val_acc: 0.3157894736842105\n",
            "epoch: 0, train_loss: 7.019191741943359, train_acc: 0.4090909090909091\n",
            "epoch: 0, val_loss: 1.1524080038070679, val_acc: 0.3157894736842105\n",
            "epoch: 1, train_loss: 1.113556981086731, train_acc: 0.390625\n",
            "epoch: 1, val_loss: 1.2507809400558472, val_acc: 0.6842105263157895\n",
            "epoch: 1, train_loss: 1.283265471458435, train_acc: 0.6875\n",
            "epoch: 1, val_loss: 1.0703259706497192, val_acc: 0.6842105263157895\n",
            "epoch: 1, train_loss: 1.021295189857483, train_acc: 0.6818181818181818\n",
            "epoch: 1, val_loss: 0.6866867542266846, val_acc: 0.6842105263157895\n",
            "epoch: 2, train_loss: 0.6853238344192505, train_acc: 0.671875\n",
            "epoch: 2, val_loss: 0.652836263179779, val_acc: 0.6052631578947368\n",
            "epoch: 2, train_loss: 0.6758686304092407, train_acc: 0.578125\n",
            "epoch: 2, val_loss: 0.7922870516777039, val_acc: 0.39473684210526316\n",
            "epoch: 2, train_loss: 0.7220101356506348, train_acc: 0.5909090909090909\n",
            "epoch: 2, val_loss: 0.7685259580612183, val_acc: 0.3157894736842105\n",
            "epoch: 3, train_loss: 0.7520740032196045, train_acc: 0.421875\n",
            "epoch: 3, val_loss: 0.660884439945221, val_acc: 0.6578947368421053\n",
            "epoch: 3, train_loss: 0.6435999274253845, train_acc: 0.640625\n",
            "epoch: 3, val_loss: 0.6031642556190491, val_acc: 0.6842105263157895\n",
            "epoch: 3, train_loss: 0.59980708360672, train_acc: 0.6818181818181818\n",
            "epoch: 3, val_loss: 0.6583374738693237, val_acc: 0.6842105263157895\n",
            "epoch: 4, train_loss: 0.7998868227005005, train_acc: 0.625\n",
            "epoch: 4, val_loss: 0.5886781811714172, val_acc: 0.6842105263157895\n",
            "epoch: 4, train_loss: 0.5900620818138123, train_acc: 0.703125\n",
            "epoch: 4, val_loss: 0.544428288936615, val_acc: 0.6842105263157895\n",
            "epoch: 4, train_loss: 0.6143216490745544, train_acc: 0.6363636363636364\n",
            "epoch: 4, val_loss: 0.6038370132446289, val_acc: 0.7631578947368421\n",
            "epoch: 5, train_loss: 0.6160349249839783, train_acc: 0.671875\n",
            "epoch: 5, val_loss: 0.59187912940979, val_acc: 0.6578947368421053\n",
            "epoch: 5, train_loss: 0.6078640222549438, train_acc: 0.6875\n",
            "epoch: 5, val_loss: 0.5366325378417969, val_acc: 0.7105263157894737\n",
            "epoch: 5, train_loss: 0.5874517560005188, train_acc: 0.6363636363636364\n",
            "epoch: 5, val_loss: 0.5295227766036987, val_acc: 0.7105263157894737\n",
            "epoch: 6, train_loss: 0.578612208366394, train_acc: 0.625\n",
            "epoch: 6, val_loss: 0.4995836615562439, val_acc: 0.7105263157894737\n",
            "epoch: 6, train_loss: 0.5135343074798584, train_acc: 0.6875\n",
            "epoch: 6, val_loss: 0.5042690634727478, val_acc: 0.7105263157894737\n",
            "epoch: 6, train_loss: 0.4098146855831146, train_acc: 0.8181818181818182\n",
            "epoch: 6, val_loss: 0.48717498779296875, val_acc: 0.7105263157894737\n",
            "epoch: 7, train_loss: 0.48359423875808716, train_acc: 0.703125\n",
            "epoch: 7, val_loss: 0.4867921769618988, val_acc: 0.7368421052631579\n",
            "epoch: 7, train_loss: 0.553260326385498, train_acc: 0.671875\n",
            "epoch: 7, val_loss: 0.4677744507789612, val_acc: 0.7105263157894737\n",
            "epoch: 7, train_loss: 0.46303510665893555, train_acc: 0.7727272727272727\n",
            "epoch: 7, val_loss: 0.530677080154419, val_acc: 0.7368421052631579\n",
            "epoch: 8, train_loss: 0.4932883381843567, train_acc: 0.75\n",
            "epoch: 8, val_loss: 0.5375699400901794, val_acc: 0.7631578947368421\n",
            "epoch: 8, train_loss: 0.48021024465560913, train_acc: 0.8125\n",
            "epoch: 8, val_loss: 0.43585139513015747, val_acc: 0.7105263157894737\n",
            "epoch: 8, train_loss: 0.5812324285507202, train_acc: 0.7727272727272727\n",
            "epoch: 8, val_loss: 0.4363841116428375, val_acc: 0.7368421052631579\n",
            "epoch: 9, train_loss: 0.3620537519454956, train_acc: 0.8125\n",
            "epoch: 9, val_loss: 0.45966652035713196, val_acc: 0.7631578947368421\n",
            "epoch: 9, train_loss: 0.4813677966594696, train_acc: 0.703125\n",
            "epoch: 9, val_loss: 0.47440409660339355, val_acc: 0.7894736842105263\n",
            "epoch: 9, train_loss: 0.4972991347312927, train_acc: 0.8636363636363636\n",
            "epoch: 9, val_loss: 0.43233606219291687, val_acc: 0.7368421052631579\n",
            "epoch: 10, train_loss: 0.3663315773010254, train_acc: 0.84375\n",
            "epoch: 10, val_loss: 0.42296209931373596, val_acc: 0.7105263157894737\n",
            "epoch: 10, train_loss: 0.559636116027832, train_acc: 0.734375\n",
            "epoch: 10, val_loss: 0.4193817973136902, val_acc: 0.7894736842105263\n",
            "epoch: 10, train_loss: 0.40390434861183167, train_acc: 0.8181818181818182\n",
            "epoch: 10, val_loss: 0.5264292359352112, val_acc: 0.7368421052631579\n",
            "epoch: 11, train_loss: 0.45398595929145813, train_acc: 0.828125\n",
            "epoch: 11, val_loss: 0.4850216805934906, val_acc: 0.7631578947368421\n",
            "epoch: 11, train_loss: 0.4294717609882355, train_acc: 0.796875\n",
            "epoch: 11, val_loss: 0.42207783460617065, val_acc: 0.7631578947368421\n",
            "epoch: 11, train_loss: 0.4309368133544922, train_acc: 0.7727272727272727\n",
            "epoch: 11, val_loss: 0.4381721317768097, val_acc: 0.7631578947368421\n",
            "epoch: 12, train_loss: 0.3059813380241394, train_acc: 0.890625\n",
            "epoch: 12, val_loss: 0.4097016751766205, val_acc: 0.7894736842105263\n",
            "epoch: 12, train_loss: 0.4656268060207367, train_acc: 0.78125\n",
            "epoch: 12, val_loss: 0.4494793713092804, val_acc: 0.7631578947368421\n",
            "epoch: 12, train_loss: 0.4263446629047394, train_acc: 0.8181818181818182\n",
            "epoch: 12, val_loss: 0.4530906677246094, val_acc: 0.8157894736842105\n",
            "epoch: 13, train_loss: 0.37510237097740173, train_acc: 0.78125\n",
            "epoch: 13, val_loss: 0.44857195019721985, val_acc: 0.7894736842105263\n",
            "epoch: 13, train_loss: 0.37215328216552734, train_acc: 0.828125\n",
            "epoch: 13, val_loss: 0.44195687770843506, val_acc: 0.8157894736842105\n",
            "epoch: 13, train_loss: 0.37190303206443787, train_acc: 0.9090909090909091\n",
            "epoch: 13, val_loss: 0.4305216670036316, val_acc: 0.7631578947368421\n",
            "epoch: 14, train_loss: 0.4750240445137024, train_acc: 0.765625\n",
            "epoch: 14, val_loss: 0.43212488293647766, val_acc: 0.7894736842105263\n",
            "epoch: 14, train_loss: 0.3873959481716156, train_acc: 0.828125\n",
            "epoch: 14, val_loss: 0.427184522151947, val_acc: 0.7894736842105263\n",
            "epoch: 14, train_loss: 0.23611049354076385, train_acc: 0.9090909090909091\n",
            "epoch: 14, val_loss: 0.4862534999847412, val_acc: 0.7894736842105263\n",
            "epoch: 15, train_loss: 0.37084609270095825, train_acc: 0.796875\n",
            "epoch: 15, val_loss: 0.5020069479942322, val_acc: 0.7368421052631579\n",
            "epoch: 15, train_loss: 0.3798942267894745, train_acc: 0.828125\n",
            "epoch: 15, val_loss: 0.41090402007102966, val_acc: 0.7631578947368421\n",
            "epoch: 15, train_loss: 0.3563670217990875, train_acc: 0.8636363636363636\n",
            "epoch: 15, val_loss: 0.43910714983940125, val_acc: 0.7368421052631579\n",
            "epoch: 16, train_loss: 0.39224812388420105, train_acc: 0.765625\n",
            "epoch: 16, val_loss: 0.4199860394001007, val_acc: 0.7368421052631579\n",
            "epoch: 16, train_loss: 0.3677707612514496, train_acc: 0.78125\n",
            "epoch: 16, val_loss: 0.556153416633606, val_acc: 0.7631578947368421\n",
            "epoch: 16, train_loss: 0.42290958762168884, train_acc: 0.8181818181818182\n",
            "epoch: 16, val_loss: 0.526952862739563, val_acc: 0.8421052631578947\n",
            "epoch: 17, train_loss: 0.3229345679283142, train_acc: 0.828125\n",
            "epoch: 17, val_loss: 0.44106367230415344, val_acc: 0.7368421052631579\n",
            "epoch: 17, train_loss: 0.3508349657058716, train_acc: 0.78125\n",
            "epoch: 17, val_loss: 0.46278923749923706, val_acc: 0.6842105263157895\n",
            "epoch: 17, train_loss: 0.35738351941108704, train_acc: 0.8181818181818182\n",
            "epoch: 17, val_loss: 0.4544556438922882, val_acc: 0.7631578947368421\n",
            "epoch: 18, train_loss: 0.4096607565879822, train_acc: 0.75\n",
            "epoch: 18, val_loss: 0.6271222829818726, val_acc: 0.7368421052631579\n",
            "epoch: 18, train_loss: 0.42792874574661255, train_acc: 0.8125\n",
            "epoch: 18, val_loss: 0.5032569766044617, val_acc: 0.8157894736842105\n",
            "epoch: 18, train_loss: 0.2813843786716461, train_acc: 0.8181818181818182\n",
            "epoch: 18, val_loss: 0.506271481513977, val_acc: 0.7631578947368421\n",
            "epoch: 19, train_loss: 0.25825420022010803, train_acc: 0.84375\n",
            "epoch: 19, val_loss: 0.4604319632053375, val_acc: 0.7631578947368421\n",
            "epoch: 19, train_loss: 0.35756874084472656, train_acc: 0.796875\n",
            "epoch: 19, val_loss: 0.5022904276847839, val_acc: 0.7894736842105263\n",
            "epoch: 19, train_loss: 0.34442684054374695, train_acc: 0.8181818181818182\n",
            "epoch: 19, val_loss: 0.501868486404419, val_acc: 0.8421052631578947\n",
            "epoch: 20, train_loss: 0.34262514114379883, train_acc: 0.796875\n",
            "epoch: 20, val_loss: 0.4800257980823517, val_acc: 0.8157894736842105\n",
            "epoch: 20, train_loss: 0.2790854871273041, train_acc: 0.859375\n",
            "epoch: 20, val_loss: 0.512872576713562, val_acc: 0.8157894736842105\n",
            "epoch: 20, train_loss: 0.27794840931892395, train_acc: 0.9090909090909091\n",
            "epoch: 20, val_loss: 0.4576806128025055, val_acc: 0.7368421052631579\n",
            "epoch: 21, train_loss: 0.37115752696990967, train_acc: 0.796875\n",
            "epoch: 21, val_loss: 0.4693773686885834, val_acc: 0.7631578947368421\n",
            "epoch: 21, train_loss: 0.26627635955810547, train_acc: 0.859375\n",
            "epoch: 21, val_loss: 0.45933935046195984, val_acc: 0.7631578947368421\n",
            "epoch: 21, train_loss: 0.17115934193134308, train_acc: 0.9090909090909091\n",
            "epoch: 21, val_loss: 0.4858388304710388, val_acc: 0.7894736842105263\n",
            "epoch: 22, train_loss: 0.27631205320358276, train_acc: 0.875\n",
            "epoch: 22, val_loss: 0.4486006796360016, val_acc: 0.7894736842105263\n",
            "epoch: 22, train_loss: 0.282895565032959, train_acc: 0.890625\n",
            "epoch: 22, val_loss: 0.4854840636253357, val_acc: 0.7894736842105263\n",
            "epoch: 22, train_loss: 0.30827441811561584, train_acc: 0.8636363636363636\n",
            "epoch: 22, val_loss: 0.48564690351486206, val_acc: 0.7631578947368421\n",
            "epoch: 23, train_loss: 0.22747911512851715, train_acc: 0.953125\n",
            "epoch: 23, val_loss: 0.519672155380249, val_acc: 0.7631578947368421\n",
            "epoch: 23, train_loss: 0.3108881711959839, train_acc: 0.890625\n",
            "epoch: 23, val_loss: 0.5020685195922852, val_acc: 0.7894736842105263\n",
            "epoch: 23, train_loss: 0.40203857421875, train_acc: 0.7727272727272727\n",
            "epoch: 23, val_loss: 0.5008898377418518, val_acc: 0.7368421052631579\n",
            "epoch: 24, train_loss: 0.3135853409767151, train_acc: 0.828125\n",
            "epoch: 24, val_loss: 0.503179669380188, val_acc: 0.7105263157894737\n",
            "epoch: 24, train_loss: 0.36583080887794495, train_acc: 0.765625\n",
            "epoch: 24, val_loss: 0.5464459657669067, val_acc: 0.7894736842105263\n",
            "epoch: 24, train_loss: 0.257805734872818, train_acc: 0.9090909090909091\n",
            "epoch: 24, val_loss: 0.5655670166015625, val_acc: 0.7894736842105263\n",
            "epoch: 25, train_loss: 0.27757254242897034, train_acc: 0.890625\n",
            "epoch: 25, val_loss: 0.5086143016815186, val_acc: 0.8157894736842105\n",
            "epoch: 25, train_loss: 0.2732953429222107, train_acc: 0.890625\n",
            "epoch: 25, val_loss: 0.5202401280403137, val_acc: 0.7631578947368421\n",
            "epoch: 25, train_loss: 0.22144001722335815, train_acc: 0.9090909090909091\n",
            "epoch: 25, val_loss: 0.5779950022697449, val_acc: 0.7631578947368421\n",
            "epoch: 26, train_loss: 0.2680646777153015, train_acc: 0.875\n",
            "epoch: 26, val_loss: 0.5512706637382507, val_acc: 0.7894736842105263\n",
            "epoch: 26, train_loss: 0.3901937007904053, train_acc: 0.8125\n",
            "epoch: 26, val_loss: 0.5457092523574829, val_acc: 0.8421052631578947\n",
            "epoch: 26, train_loss: 0.26349109411239624, train_acc: 0.9545454545454546\n",
            "epoch: 26, val_loss: 0.6584969162940979, val_acc: 0.7894736842105263\n",
            "epoch: 27, train_loss: 0.3642464578151703, train_acc: 0.796875\n",
            "epoch: 27, val_loss: 0.5438147187232971, val_acc: 0.8157894736842105\n",
            "epoch: 27, train_loss: 0.2616333067417145, train_acc: 0.890625\n",
            "epoch: 27, val_loss: 0.5172297954559326, val_acc: 0.7631578947368421\n",
            "epoch: 27, train_loss: 0.36361566185951233, train_acc: 0.7727272727272727\n",
            "epoch: 27, val_loss: 0.49268683791160583, val_acc: 0.8421052631578947\n",
            "epoch: 28, train_loss: 0.24647118151187897, train_acc: 0.9375\n",
            "epoch: 28, val_loss: 0.5087370276451111, val_acc: 0.8421052631578947\n",
            "epoch: 28, train_loss: 0.23044592142105103, train_acc: 0.90625\n",
            "epoch: 28, val_loss: 0.5588647723197937, val_acc: 0.8157894736842105\n",
            "epoch: 28, train_loss: 0.3039787709712982, train_acc: 0.9090909090909091\n",
            "epoch: 28, val_loss: 0.5713051557540894, val_acc: 0.8421052631578947\n",
            "epoch: 29, train_loss: 0.2570247948169708, train_acc: 0.84375\n",
            "epoch: 29, val_loss: 0.5764272809028625, val_acc: 0.7368421052631579\n",
            "epoch: 29, train_loss: 0.36339646577835083, train_acc: 0.75\n",
            "epoch: 29, val_loss: 0.5593267679214478, val_acc: 0.8157894736842105\n",
            "epoch: 29, train_loss: 0.19471752643585205, train_acc: 0.9090909090909091\n",
            "epoch: 29, val_loss: 0.6197140216827393, val_acc: 0.8157894736842105\n",
            "epoch: 30, train_loss: 0.28172212839126587, train_acc: 0.890625\n",
            "epoch: 30, val_loss: 0.6982439160346985, val_acc: 0.8157894736842105\n",
            "epoch: 30, train_loss: 0.336942195892334, train_acc: 0.828125\n",
            "epoch: 30, val_loss: 0.6831002831459045, val_acc: 0.8421052631578947\n",
            "epoch: 30, train_loss: 0.16451852023601532, train_acc: 0.9545454545454546\n",
            "epoch: 30, val_loss: 0.6290521025657654, val_acc: 0.7894736842105263\n",
            "epoch: 31, train_loss: 0.22191393375396729, train_acc: 0.890625\n",
            "epoch: 31, val_loss: 0.5963870286941528, val_acc: 0.7894736842105263\n",
            "epoch: 31, train_loss: 0.32101231813430786, train_acc: 0.828125\n",
            "epoch: 31, val_loss: 0.6212746500968933, val_acc: 0.8157894736842105\n",
            "epoch: 31, train_loss: 0.3364570140838623, train_acc: 0.8181818181818182\n",
            "epoch: 31, val_loss: 0.667927086353302, val_acc: 0.8157894736842105\n",
            "epoch: 32, train_loss: 0.24665074050426483, train_acc: 0.890625\n",
            "epoch: 32, val_loss: 0.8022871613502502, val_acc: 0.7894736842105263\n",
            "epoch: 32, train_loss: 0.5542428493499756, train_acc: 0.703125\n",
            "epoch: 32, val_loss: 0.5786439776420593, val_acc: 0.7894736842105263\n",
            "epoch: 32, train_loss: 0.21362723410129547, train_acc: 0.9090909090909091\n",
            "epoch: 32, val_loss: 0.628075122833252, val_acc: 0.7368421052631579\n",
            "epoch: 33, train_loss: 0.37888598442077637, train_acc: 0.796875\n",
            "epoch: 33, val_loss: 0.6058952808380127, val_acc: 0.7368421052631579\n",
            "epoch: 33, train_loss: 0.27830934524536133, train_acc: 0.859375\n",
            "epoch: 33, val_loss: 0.5377402305603027, val_acc: 0.7894736842105263\n",
            "epoch: 33, train_loss: 0.3816686272621155, train_acc: 0.8181818181818182\n",
            "epoch: 33, val_loss: 0.695684015750885, val_acc: 0.8421052631578947\n",
            "epoch: 34, train_loss: 0.27344730496406555, train_acc: 0.875\n",
            "epoch: 34, val_loss: 0.8955579996109009, val_acc: 0.631578947368421\n",
            "epoch: 34, train_loss: 0.6433981657028198, train_acc: 0.65625\n",
            "epoch: 34, val_loss: 0.5797396302223206, val_acc: 0.8157894736842105\n",
            "epoch: 34, train_loss: 0.33709874749183655, train_acc: 0.8636363636363636\n",
            "epoch: 34, val_loss: 0.5292189717292786, val_acc: 0.7368421052631579\n",
            "epoch: 35, train_loss: 0.2767626643180847, train_acc: 0.8125\n",
            "epoch: 35, val_loss: 0.6553556323051453, val_acc: 0.7368421052631579\n",
            "epoch: 35, train_loss: 0.41733822226524353, train_acc: 0.8125\n",
            "epoch: 35, val_loss: 0.5925297737121582, val_acc: 0.7105263157894737\n",
            "epoch: 35, train_loss: 0.4057939946651459, train_acc: 0.8181818181818182\n",
            "epoch: 35, val_loss: 0.5345016121864319, val_acc: 0.7894736842105263\n",
            "epoch: 36, train_loss: 0.23180340230464935, train_acc: 0.890625\n",
            "epoch: 36, val_loss: 0.4958805739879608, val_acc: 0.8157894736842105\n",
            "epoch: 36, train_loss: 0.20936626195907593, train_acc: 0.921875\n",
            "epoch: 36, val_loss: 0.5867050886154175, val_acc: 0.7894736842105263\n",
            "epoch: 36, train_loss: 0.46089884638786316, train_acc: 0.8181818181818182\n",
            "epoch: 36, val_loss: 0.5991122126579285, val_acc: 0.7894736842105263\n",
            "epoch: 37, train_loss: 0.3486672043800354, train_acc: 0.875\n",
            "epoch: 37, val_loss: 0.5046888589859009, val_acc: 0.8421052631578947\n",
            "epoch: 37, train_loss: 0.2579490542411804, train_acc: 0.921875\n",
            "epoch: 37, val_loss: 0.47757530212402344, val_acc: 0.7894736842105263\n",
            "epoch: 37, train_loss: 0.19377145171165466, train_acc: 1.0\n",
            "epoch: 37, val_loss: 0.4531635642051697, val_acc: 0.8157894736842105\n",
            "epoch: 38, train_loss: 0.24670572578907013, train_acc: 0.875\n",
            "epoch: 38, val_loss: 0.5221176743507385, val_acc: 0.7894736842105263\n",
            "epoch: 38, train_loss: 0.2816731333732605, train_acc: 0.875\n",
            "epoch: 38, val_loss: 0.503076434135437, val_acc: 0.8421052631578947\n",
            "epoch: 38, train_loss: 0.14169934391975403, train_acc: 0.9545454545454546\n",
            "epoch: 38, val_loss: 0.5323469042778015, val_acc: 0.8421052631578947\n",
            "epoch: 39, train_loss: 0.26247772574424744, train_acc: 0.890625\n",
            "epoch: 39, val_loss: 0.4840497076511383, val_acc: 0.8421052631578947\n",
            "epoch: 39, train_loss: 0.22472935914993286, train_acc: 0.90625\n",
            "epoch: 39, val_loss: 0.5172315835952759, val_acc: 0.8421052631578947\n",
            "epoch: 39, train_loss: 0.21129369735717773, train_acc: 0.9090909090909091\n",
            "epoch: 39, val_loss: 0.5297032594680786, val_acc: 0.8421052631578947\n",
            "epoch: 40, train_loss: 0.1867363154888153, train_acc: 0.921875\n",
            "epoch: 40, val_loss: 0.5645223259925842, val_acc: 0.8421052631578947\n",
            "epoch: 40, train_loss: 0.2750367522239685, train_acc: 0.8125\n",
            "epoch: 40, val_loss: 0.5033740997314453, val_acc: 0.8421052631578947\n",
            "epoch: 40, train_loss: 0.24060861766338348, train_acc: 0.9545454545454546\n",
            "epoch: 40, val_loss: 0.5758649110794067, val_acc: 0.8421052631578947\n",
            "epoch: 41, train_loss: 0.2335260808467865, train_acc: 0.890625\n",
            "epoch: 41, val_loss: 0.5325625538825989, val_acc: 0.8421052631578947\n",
            "epoch: 41, train_loss: 0.21385632455348969, train_acc: 0.890625\n",
            "epoch: 41, val_loss: 0.5394629836082458, val_acc: 0.8157894736842105\n",
            "epoch: 41, train_loss: 0.12302543967962265, train_acc: 1.0\n",
            "epoch: 41, val_loss: 0.5427554249763489, val_acc: 0.8157894736842105\n",
            "epoch: 42, train_loss: 0.24627822637557983, train_acc: 0.9375\n",
            "epoch: 42, val_loss: 0.5356599688529968, val_acc: 0.8421052631578947\n",
            "epoch: 42, train_loss: 0.18814235925674438, train_acc: 0.921875\n",
            "epoch: 42, val_loss: 0.5443814992904663, val_acc: 0.8421052631578947\n",
            "epoch: 42, train_loss: 0.20519022643566132, train_acc: 0.8636363636363636\n",
            "epoch: 42, val_loss: 0.4851149916648865, val_acc: 0.8157894736842105\n",
            "epoch: 43, train_loss: 0.23352420330047607, train_acc: 0.875\n",
            "epoch: 43, val_loss: 0.4814099669456482, val_acc: 0.8421052631578947\n",
            "epoch: 43, train_loss: 0.21262845396995544, train_acc: 0.921875\n",
            "epoch: 43, val_loss: 0.5022493600845337, val_acc: 0.868421052631579\n",
            "epoch: 43, train_loss: 0.2569085955619812, train_acc: 0.8636363636363636\n",
            "epoch: 43, val_loss: 0.521944522857666, val_acc: 0.8157894736842105\n",
            "epoch: 44, train_loss: 0.22688862681388855, train_acc: 0.890625\n",
            "epoch: 44, val_loss: 0.5332332253456116, val_acc: 0.8157894736842105\n",
            "epoch: 44, train_loss: 0.2653023600578308, train_acc: 0.875\n",
            "epoch: 44, val_loss: 0.5284180045127869, val_acc: 0.868421052631579\n",
            "epoch: 44, train_loss: 0.1550891399383545, train_acc: 0.9545454545454546\n",
            "epoch: 44, val_loss: 0.5076050758361816, val_acc: 0.8421052631578947\n",
            "epoch: 45, train_loss: 0.28437352180480957, train_acc: 0.875\n",
            "epoch: 45, val_loss: 0.5550939440727234, val_acc: 0.8157894736842105\n",
            "epoch: 45, train_loss: 0.13794168829917908, train_acc: 0.953125\n",
            "epoch: 45, val_loss: 0.5156926512718201, val_acc: 0.8421052631578947\n",
            "epoch: 45, train_loss: 0.1544770747423172, train_acc: 0.9090909090909091\n",
            "epoch: 45, val_loss: 0.5360385775566101, val_acc: 0.8421052631578947\n",
            "epoch: 46, train_loss: 0.2936933934688568, train_acc: 0.84375\n",
            "epoch: 46, val_loss: 0.5455907583236694, val_acc: 0.8421052631578947\n",
            "epoch: 46, train_loss: 0.14312049746513367, train_acc: 0.921875\n",
            "epoch: 46, val_loss: 0.5737373232841492, val_acc: 0.8421052631578947\n",
            "epoch: 46, train_loss: 0.09910919517278671, train_acc: 0.9545454545454546\n",
            "epoch: 46, val_loss: 0.6152361631393433, val_acc: 0.8421052631578947\n",
            "epoch: 47, train_loss: 0.20830383896827698, train_acc: 0.921875\n",
            "epoch: 47, val_loss: 0.6338537335395813, val_acc: 0.8421052631578947\n",
            "epoch: 47, train_loss: 0.2064615786075592, train_acc: 0.921875\n",
            "epoch: 47, val_loss: 0.547866702079773, val_acc: 0.8421052631578947\n",
            "epoch: 47, train_loss: 0.12346043437719345, train_acc: 0.9545454545454546\n",
            "epoch: 47, val_loss: 0.6315790414810181, val_acc: 0.8421052631578947\n",
            "epoch: 48, train_loss: 0.11964660882949829, train_acc: 0.953125\n",
            "epoch: 48, val_loss: 0.6407463550567627, val_acc: 0.8421052631578947\n",
            "epoch: 48, train_loss: 0.2230539619922638, train_acc: 0.9375\n",
            "epoch: 48, val_loss: 0.6038260459899902, val_acc: 0.8421052631578947\n",
            "epoch: 48, train_loss: 0.24397484958171844, train_acc: 0.8636363636363636\n",
            "epoch: 48, val_loss: 0.6260588765144348, val_acc: 0.8421052631578947\n",
            "epoch: 49, train_loss: 0.11002838611602783, train_acc: 0.953125\n",
            "epoch: 49, val_loss: 0.6202679872512817, val_acc: 0.8421052631578947\n",
            "epoch: 49, train_loss: 0.22620734572410583, train_acc: 0.921875\n",
            "epoch: 49, val_loss: 0.5832064151763916, val_acc: 0.8421052631578947\n",
            "epoch: 49, train_loss: 0.3000901937484741, train_acc: 0.9545454545454546\n",
            "epoch: 49, val_loss: 0.6517965197563171, val_acc: 0.8421052631578947\n",
            "epoch: 50, train_loss: 0.2148849368095398, train_acc: 0.890625\n",
            "epoch: 50, val_loss: 0.5899683237075806, val_acc: 0.8421052631578947\n",
            "epoch: 50, train_loss: 0.2041991949081421, train_acc: 0.90625\n",
            "epoch: 50, val_loss: 0.5592120289802551, val_acc: 0.8421052631578947\n",
            "epoch: 50, train_loss: 0.0698687955737114, train_acc: 1.0\n",
            "epoch: 50, val_loss: 0.6141454577445984, val_acc: 0.8421052631578947\n",
            "epoch: 51, train_loss: 0.2452884167432785, train_acc: 0.875\n",
            "epoch: 51, val_loss: 0.6432704925537109, val_acc: 0.7894736842105263\n",
            "epoch: 51, train_loss: 0.17503556609153748, train_acc: 0.90625\n",
            "epoch: 51, val_loss: 0.5486289858818054, val_acc: 0.8157894736842105\n",
            "epoch: 51, train_loss: 0.10942079871892929, train_acc: 0.9545454545454546\n",
            "epoch: 51, val_loss: 0.6586943864822388, val_acc: 0.8421052631578947\n",
            "epoch: 52, train_loss: 0.23831206560134888, train_acc: 0.9375\n",
            "epoch: 52, val_loss: 0.6178518533706665, val_acc: 0.8157894736842105\n",
            "epoch: 52, train_loss: 0.18165460228919983, train_acc: 0.90625\n",
            "epoch: 52, val_loss: 0.5795575976371765, val_acc: 0.8421052631578947\n",
            "epoch: 52, train_loss: 0.15054357051849365, train_acc: 0.9090909090909091\n",
            "epoch: 52, val_loss: 0.5755317807197571, val_acc: 0.8157894736842105\n",
            "epoch: 53, train_loss: 0.13821405172348022, train_acc: 0.953125\n",
            "epoch: 53, val_loss: 0.5102108716964722, val_acc: 0.7894736842105263\n",
            "epoch: 53, train_loss: 0.28957241773605347, train_acc: 0.8125\n",
            "epoch: 53, val_loss: 0.5787676572799683, val_acc: 0.7368421052631579\n",
            "epoch: 53, train_loss: 0.18934769928455353, train_acc: 0.8636363636363636\n",
            "epoch: 53, val_loss: 0.7191933393478394, val_acc: 0.8157894736842105\n",
            "epoch: 54, train_loss: 0.42356789112091064, train_acc: 0.78125\n",
            "epoch: 54, val_loss: 0.5913088917732239, val_acc: 0.8157894736842105\n",
            "epoch: 54, train_loss: 0.22462064027786255, train_acc: 0.890625\n",
            "epoch: 54, val_loss: 0.6437984108924866, val_acc: 0.7894736842105263\n",
            "epoch: 54, train_loss: 0.30436575412750244, train_acc: 0.9090909090909091\n",
            "epoch: 54, val_loss: 0.626056969165802, val_acc: 0.7894736842105263\n",
            "epoch: 55, train_loss: 0.1557627022266388, train_acc: 0.90625\n",
            "epoch: 55, val_loss: 0.5910069346427917, val_acc: 0.8157894736842105\n",
            "epoch: 55, train_loss: 0.30705010890960693, train_acc: 0.859375\n",
            "epoch: 55, val_loss: 0.6984013915061951, val_acc: 0.8421052631578947\n",
            "epoch: 55, train_loss: 0.10568162798881531, train_acc: 0.9545454545454546\n",
            "epoch: 55, val_loss: 0.8378605842590332, val_acc: 0.7368421052631579\n",
            "epoch: 56, train_loss: 0.3599070906639099, train_acc: 0.828125\n",
            "epoch: 56, val_loss: 0.5912545919418335, val_acc: 0.8421052631578947\n",
            "epoch: 56, train_loss: 0.2597028613090515, train_acc: 0.90625\n",
            "epoch: 56, val_loss: 0.6286011934280396, val_acc: 0.7894736842105263\n",
            "epoch: 56, train_loss: 0.2761046290397644, train_acc: 0.8181818181818182\n",
            "epoch: 56, val_loss: 0.6297476887702942, val_acc: 0.7631578947368421\n",
            "epoch: 57, train_loss: 0.2901257276535034, train_acc: 0.859375\n",
            "epoch: 57, val_loss: 0.6307184100151062, val_acc: 0.7894736842105263\n",
            "epoch: 57, train_loss: 0.22250808775424957, train_acc: 0.875\n",
            "epoch: 57, val_loss: 0.5667303204536438, val_acc: 0.8421052631578947\n",
            "epoch: 57, train_loss: 0.10990182310342789, train_acc: 0.9545454545454546\n",
            "epoch: 57, val_loss: 0.7845291495323181, val_acc: 0.8157894736842105\n",
            "epoch: 58, train_loss: 0.2929016053676605, train_acc: 0.84375\n",
            "epoch: 58, val_loss: 0.7587943077087402, val_acc: 0.7894736842105263\n",
            "epoch: 58, train_loss: 0.3744925558567047, train_acc: 0.859375\n",
            "epoch: 58, val_loss: 0.5534864664077759, val_acc: 0.8157894736842105\n",
            "epoch: 58, train_loss: 0.2709154188632965, train_acc: 0.8181818181818182\n",
            "epoch: 58, val_loss: 0.6430752873420715, val_acc: 0.7105263157894737\n",
            "epoch: 59, train_loss: 0.35606178641319275, train_acc: 0.8125\n",
            "epoch: 59, val_loss: 0.621032178401947, val_acc: 0.7105263157894737\n",
            "epoch: 59, train_loss: 0.339188814163208, train_acc: 0.859375\n",
            "epoch: 59, val_loss: 0.5758115649223328, val_acc: 0.7105263157894737\n",
            "epoch: 59, train_loss: 0.27493369579315186, train_acc: 0.9090909090909091\n",
            "epoch: 59, val_loss: 0.5594332218170166, val_acc: 0.8421052631578947\n",
            "epoch: 60, train_loss: 0.14687669277191162, train_acc: 0.921875\n",
            "epoch: 60, val_loss: 0.6234683990478516, val_acc: 0.8157894736842105\n",
            "epoch: 60, train_loss: 0.32805532217025757, train_acc: 0.875\n",
            "epoch: 60, val_loss: 0.7128639221191406, val_acc: 0.8157894736842105\n",
            "epoch: 60, train_loss: 0.20413202047348022, train_acc: 0.9090909090909091\n",
            "epoch: 60, val_loss: 0.6503401398658752, val_acc: 0.8421052631578947\n",
            "epoch: 61, train_loss: 0.17562294006347656, train_acc: 0.9375\n",
            "epoch: 61, val_loss: 0.577993631362915, val_acc: 0.8421052631578947\n",
            "epoch: 61, train_loss: 0.23932276666164398, train_acc: 0.890625\n",
            "epoch: 61, val_loss: 0.6530941724777222, val_acc: 0.8157894736842105\n",
            "epoch: 61, train_loss: 0.15331655740737915, train_acc: 0.9090909090909091\n",
            "epoch: 61, val_loss: 0.6301500201225281, val_acc: 0.7894736842105263\n",
            "epoch: 62, train_loss: 0.18495646119117737, train_acc: 0.890625\n",
            "epoch: 62, val_loss: 0.5892664194107056, val_acc: 0.7894736842105263\n",
            "epoch: 62, train_loss: 0.5378037691116333, train_acc: 0.828125\n",
            "epoch: 62, val_loss: 0.5561612844467163, val_acc: 0.7894736842105263\n",
            "epoch: 62, train_loss: 0.2556385099887848, train_acc: 0.8636363636363636\n",
            "epoch: 62, val_loss: 0.5468708872795105, val_acc: 0.8157894736842105\n",
            "epoch: 63, train_loss: 0.19468377530574799, train_acc: 0.875\n",
            "epoch: 63, val_loss: 0.6116276383399963, val_acc: 0.8157894736842105\n",
            "epoch: 63, train_loss: 0.19647738337516785, train_acc: 0.921875\n",
            "epoch: 63, val_loss: 0.6502198576927185, val_acc: 0.7894736842105263\n",
            "epoch: 63, train_loss: 0.43873393535614014, train_acc: 0.7272727272727273\n",
            "epoch: 63, val_loss: 0.5416280627250671, val_acc: 0.8157894736842105\n",
            "epoch: 64, train_loss: 0.28253060579299927, train_acc: 0.90625\n",
            "epoch: 64, val_loss: 0.46967580914497375, val_acc: 0.7894736842105263\n",
            "epoch: 64, train_loss: 0.21253269910812378, train_acc: 0.890625\n",
            "epoch: 64, val_loss: 0.5262977480888367, val_acc: 0.7631578947368421\n",
            "epoch: 64, train_loss: 0.06378591805696487, train_acc: 0.9545454545454546\n",
            "epoch: 64, val_loss: 0.5797015428543091, val_acc: 0.7631578947368421\n",
            "epoch: 65, train_loss: 0.3380560278892517, train_acc: 0.796875\n",
            "epoch: 65, val_loss: 0.5412713885307312, val_acc: 0.7631578947368421\n",
            "epoch: 65, train_loss: 0.23637655377388, train_acc: 0.890625\n",
            "epoch: 65, val_loss: 0.5379584431648254, val_acc: 0.7894736842105263\n",
            "epoch: 65, train_loss: 0.23453830182552338, train_acc: 0.8636363636363636\n",
            "epoch: 65, val_loss: 0.505583643913269, val_acc: 0.7631578947368421\n",
            "epoch: 66, train_loss: 0.18991723656654358, train_acc: 0.890625\n",
            "epoch: 66, val_loss: 0.45465174317359924, val_acc: 0.8421052631578947\n",
            "epoch: 66, train_loss: 0.20965303480625153, train_acc: 0.921875\n",
            "epoch: 66, val_loss: 0.5075947642326355, val_acc: 0.8421052631578947\n",
            "epoch: 66, train_loss: 0.2409312129020691, train_acc: 0.9090909090909091\n",
            "epoch: 66, val_loss: 0.5422611236572266, val_acc: 0.8421052631578947\n",
            "epoch: 67, train_loss: 0.2692849040031433, train_acc: 0.890625\n",
            "epoch: 67, val_loss: 0.5197089910507202, val_acc: 0.8421052631578947\n",
            "epoch: 67, train_loss: 0.18553560972213745, train_acc: 0.921875\n",
            "epoch: 67, val_loss: 0.4566277861595154, val_acc: 0.8421052631578947\n",
            "epoch: 67, train_loss: 0.16783958673477173, train_acc: 0.9090909090909091\n",
            "epoch: 67, val_loss: 0.5644385814666748, val_acc: 0.8157894736842105\n",
            "epoch: 68, train_loss: 0.22502148151397705, train_acc: 0.890625\n",
            "epoch: 68, val_loss: 0.5546646118164062, val_acc: 0.8157894736842105\n",
            "epoch: 68, train_loss: 0.1747473180294037, train_acc: 0.90625\n",
            "epoch: 68, val_loss: 0.5615177154541016, val_acc: 0.8157894736842105\n",
            "epoch: 68, train_loss: 0.22154249250888824, train_acc: 0.8181818181818182\n",
            "epoch: 68, val_loss: 0.5933262705802917, val_acc: 0.8421052631578947\n",
            "epoch: 69, train_loss: 0.1738329827785492, train_acc: 0.921875\n",
            "epoch: 69, val_loss: 0.5482761263847351, val_acc: 0.8421052631578947\n",
            "epoch: 69, train_loss: 0.27606186270713806, train_acc: 0.84375\n",
            "epoch: 69, val_loss: 0.6053610444068909, val_acc: 0.7894736842105263\n",
            "epoch: 69, train_loss: 0.13146531581878662, train_acc: 0.9545454545454546\n",
            "epoch: 69, val_loss: 0.5863649249076843, val_acc: 0.8421052631578947\n",
            "epoch: 70, train_loss: 0.21051962673664093, train_acc: 0.875\n",
            "epoch: 70, val_loss: 0.5548538565635681, val_acc: 0.7894736842105263\n",
            "epoch: 70, train_loss: 0.1657669097185135, train_acc: 0.90625\n",
            "epoch: 70, val_loss: 0.5550951957702637, val_acc: 0.7894736842105263\n",
            "epoch: 70, train_loss: 0.1512095034122467, train_acc: 0.9545454545454546\n",
            "epoch: 70, val_loss: 0.5609075427055359, val_acc: 0.8421052631578947\n",
            "epoch: 71, train_loss: 0.2184021770954132, train_acc: 0.890625\n",
            "epoch: 71, val_loss: 0.5265511870384216, val_acc: 0.8157894736842105\n",
            "epoch: 71, train_loss: 0.1539134979248047, train_acc: 0.921875\n",
            "epoch: 71, val_loss: 0.5254733562469482, val_acc: 0.7894736842105263\n",
            "epoch: 71, train_loss: 0.13479650020599365, train_acc: 0.9545454545454546\n",
            "epoch: 71, val_loss: 0.5322751998901367, val_acc: 0.8157894736842105\n",
            "epoch: 72, train_loss: 0.1738673448562622, train_acc: 0.9375\n",
            "epoch: 72, val_loss: 0.6077269315719604, val_acc: 0.8421052631578947\n",
            "epoch: 72, train_loss: 0.18106114864349365, train_acc: 0.9375\n",
            "epoch: 72, val_loss: 0.6302773356437683, val_acc: 0.8157894736842105\n",
            "epoch: 72, train_loss: 0.1853133887052536, train_acc: 0.9090909090909091\n",
            "epoch: 72, val_loss: 0.608594536781311, val_acc: 0.7894736842105263\n",
            "epoch: 73, train_loss: 0.15681251883506775, train_acc: 0.921875\n",
            "epoch: 73, val_loss: 0.5642924308776855, val_acc: 0.7894736842105263\n",
            "epoch: 73, train_loss: 0.26667529344558716, train_acc: 0.859375\n",
            "epoch: 73, val_loss: 0.5823835134506226, val_acc: 0.7894736842105263\n",
            "epoch: 73, train_loss: 0.1711888313293457, train_acc: 0.8636363636363636\n",
            "epoch: 73, val_loss: 0.7178203463554382, val_acc: 0.8157894736842105\n",
            "epoch: 74, train_loss: 0.18156865239143372, train_acc: 0.9375\n",
            "epoch: 74, val_loss: 0.734130859375, val_acc: 0.7631578947368421\n",
            "epoch: 74, train_loss: 0.3306218981742859, train_acc: 0.84375\n",
            "epoch: 74, val_loss: 0.5884309411048889, val_acc: 0.8421052631578947\n",
            "epoch: 74, train_loss: 0.16324280202388763, train_acc: 0.9090909090909091\n",
            "epoch: 74, val_loss: 0.5750529766082764, val_acc: 0.7894736842105263\n",
            "epoch: 75, train_loss: 0.16857297718524933, train_acc: 0.90625\n",
            "epoch: 75, val_loss: 0.5659191608428955, val_acc: 0.7368421052631579\n",
            "epoch: 75, train_loss: 0.23305244743824005, train_acc: 0.890625\n",
            "epoch: 75, val_loss: 0.5736023783683777, val_acc: 0.7631578947368421\n",
            "epoch: 75, train_loss: 0.14894935488700867, train_acc: 0.9090909090909091\n",
            "epoch: 75, val_loss: 0.5773025155067444, val_acc: 0.7631578947368421\n",
            "epoch: 76, train_loss: 0.18351471424102783, train_acc: 0.90625\n",
            "epoch: 76, val_loss: 0.5068262219429016, val_acc: 0.7631578947368421\n",
            "epoch: 76, train_loss: 0.18813316524028778, train_acc: 0.875\n",
            "epoch: 76, val_loss: 0.47350242733955383, val_acc: 0.7894736842105263\n",
            "epoch: 76, train_loss: 0.22437962889671326, train_acc: 0.9090909090909091\n",
            "epoch: 76, val_loss: 0.47855839133262634, val_acc: 0.8157894736842105\n",
            "epoch: 77, train_loss: 0.1989738941192627, train_acc: 0.921875\n",
            "epoch: 77, val_loss: 0.5051931738853455, val_acc: 0.8157894736842105\n",
            "epoch: 77, train_loss: 0.2032838761806488, train_acc: 0.921875\n",
            "epoch: 77, val_loss: 0.4900977909564972, val_acc: 0.8157894736842105\n",
            "epoch: 77, train_loss: 0.07125739008188248, train_acc: 1.0\n",
            "epoch: 77, val_loss: 0.5286394953727722, val_acc: 0.8157894736842105\n",
            "epoch: 78, train_loss: 0.18053916096687317, train_acc: 0.921875\n",
            "epoch: 78, val_loss: 0.5209062695503235, val_acc: 0.7894736842105263\n",
            "epoch: 78, train_loss: 0.14011141657829285, train_acc: 0.9375\n",
            "epoch: 78, val_loss: 0.5441036224365234, val_acc: 0.7894736842105263\n",
            "epoch: 78, train_loss: 0.31889256834983826, train_acc: 0.8181818181818182\n",
            "epoch: 78, val_loss: 0.5353821516036987, val_acc: 0.7894736842105263\n",
            "epoch: 79, train_loss: 0.17308586835861206, train_acc: 0.890625\n",
            "epoch: 79, val_loss: 0.5360610485076904, val_acc: 0.7894736842105263\n",
            "epoch: 79, train_loss: 0.15342022478580475, train_acc: 0.9375\n",
            "epoch: 79, val_loss: 0.5275344252586365, val_acc: 0.7894736842105263\n",
            "epoch: 79, train_loss: 0.19448184967041016, train_acc: 0.9090909090909091\n",
            "epoch: 79, val_loss: 0.5960353016853333, val_acc: 0.8157894736842105\n",
            "epoch: 80, train_loss: 0.1137971580028534, train_acc: 0.96875\n",
            "epoch: 80, val_loss: 0.6148549914360046, val_acc: 0.8157894736842105\n",
            "epoch: 80, train_loss: 0.25561368465423584, train_acc: 0.859375\n",
            "epoch: 80, val_loss: 0.55692058801651, val_acc: 0.7894736842105263\n",
            "epoch: 80, train_loss: 0.16412395238876343, train_acc: 0.9090909090909091\n",
            "epoch: 80, val_loss: 0.5443023443222046, val_acc: 0.7894736842105263\n",
            "epoch: 81, train_loss: 0.18260781466960907, train_acc: 0.921875\n",
            "epoch: 81, val_loss: 0.5510150790214539, val_acc: 0.8157894736842105\n",
            "epoch: 81, train_loss: 0.15350452065467834, train_acc: 0.9375\n",
            "epoch: 81, val_loss: 0.5264785885810852, val_acc: 0.7894736842105263\n",
            "epoch: 81, train_loss: 0.22972671687602997, train_acc: 0.8636363636363636\n",
            "epoch: 81, val_loss: 0.5452547669410706, val_acc: 0.7894736842105263\n",
            "epoch: 82, train_loss: 0.12699146568775177, train_acc: 0.921875\n",
            "epoch: 82, val_loss: 0.5649474859237671, val_acc: 0.8157894736842105\n",
            "epoch: 82, train_loss: 0.1719450056552887, train_acc: 0.921875\n",
            "epoch: 82, val_loss: 0.5922365188598633, val_acc: 0.8157894736842105\n",
            "epoch: 82, train_loss: 0.20850059390068054, train_acc: 0.9090909090909091\n",
            "epoch: 82, val_loss: 0.6085627675056458, val_acc: 0.8157894736842105\n",
            "epoch: 83, train_loss: 0.1362343430519104, train_acc: 0.96875\n",
            "epoch: 83, val_loss: 0.5774439573287964, val_acc: 0.8421052631578947\n",
            "epoch: 83, train_loss: 0.19017893075942993, train_acc: 0.9375\n",
            "epoch: 83, val_loss: 0.5580178499221802, val_acc: 0.8421052631578947\n",
            "epoch: 83, train_loss: 0.20258820056915283, train_acc: 0.8636363636363636\n",
            "epoch: 83, val_loss: 0.5567517280578613, val_acc: 0.8157894736842105\n",
            "epoch: 84, train_loss: 0.1586969494819641, train_acc: 0.9375\n",
            "epoch: 84, val_loss: 0.6035483479499817, val_acc: 0.8157894736842105\n",
            "epoch: 84, train_loss: 0.14534294605255127, train_acc: 0.953125\n",
            "epoch: 84, val_loss: 0.5890597105026245, val_acc: 0.7894736842105263\n",
            "epoch: 84, train_loss: 0.15264004468917847, train_acc: 0.9545454545454546\n",
            "epoch: 84, val_loss: 0.5155014991760254, val_acc: 0.8157894736842105\n",
            "epoch: 85, train_loss: 0.11949654668569565, train_acc: 0.96875\n",
            "epoch: 85, val_loss: 0.5831180214881897, val_acc: 0.8421052631578947\n",
            "epoch: 85, train_loss: 0.13121771812438965, train_acc: 0.9375\n",
            "epoch: 85, val_loss: 0.5697748064994812, val_acc: 0.8421052631578947\n",
            "epoch: 85, train_loss: 0.30516210198402405, train_acc: 0.8636363636363636\n",
            "epoch: 85, val_loss: 0.5813196301460266, val_acc: 0.8157894736842105\n",
            "epoch: 86, train_loss: 0.11257657408714294, train_acc: 0.921875\n",
            "epoch: 86, val_loss: 0.5942985415458679, val_acc: 0.7894736842105263\n",
            "epoch: 86, train_loss: 0.19047194719314575, train_acc: 0.90625\n",
            "epoch: 86, val_loss: 0.5408355593681335, val_acc: 0.8157894736842105\n",
            "epoch: 86, train_loss: 0.19355809688568115, train_acc: 0.9090909090909091\n",
            "epoch: 86, val_loss: 0.5726539492607117, val_acc: 0.8421052631578947\n",
            "epoch: 87, train_loss: 0.2052844762802124, train_acc: 0.921875\n",
            "epoch: 87, val_loss: 0.5565162897109985, val_acc: 0.8157894736842105\n",
            "epoch: 87, train_loss: 0.17681565880775452, train_acc: 0.921875\n",
            "epoch: 87, val_loss: 0.5481972694396973, val_acc: 0.8157894736842105\n",
            "epoch: 87, train_loss: 0.10386501997709274, train_acc: 0.9545454545454546\n",
            "epoch: 87, val_loss: 0.5630626082420349, val_acc: 0.7631578947368421\n",
            "epoch: 88, train_loss: 0.15512539446353912, train_acc: 0.921875\n",
            "epoch: 88, val_loss: 0.5708216428756714, val_acc: 0.7368421052631579\n",
            "epoch: 88, train_loss: 0.14120161533355713, train_acc: 0.921875\n",
            "epoch: 88, val_loss: 0.5874044895172119, val_acc: 0.7894736842105263\n",
            "epoch: 88, train_loss: 0.25959163904190063, train_acc: 0.7272727272727273\n",
            "epoch: 88, val_loss: 0.5149251818656921, val_acc: 0.8421052631578947\n",
            "epoch: 89, train_loss: 0.16635844111442566, train_acc: 0.90625\n",
            "epoch: 89, val_loss: 0.6435510516166687, val_acc: 0.8157894736842105\n",
            "epoch: 89, train_loss: 0.16907642781734467, train_acc: 0.90625\n",
            "epoch: 89, val_loss: 0.6762339472770691, val_acc: 0.7894736842105263\n",
            "epoch: 89, train_loss: 0.4722590148448944, train_acc: 0.8636363636363636\n",
            "epoch: 89, val_loss: 0.5576647520065308, val_acc: 0.7894736842105263\n",
            "epoch: 90, train_loss: 0.13785162568092346, train_acc: 0.953125\n",
            "epoch: 90, val_loss: 0.593819260597229, val_acc: 0.7631578947368421\n",
            "epoch: 90, train_loss: 0.3098875880241394, train_acc: 0.84375\n",
            "epoch: 90, val_loss: 0.6123973727226257, val_acc: 0.7631578947368421\n",
            "epoch: 90, train_loss: 0.30384641885757446, train_acc: 0.8636363636363636\n",
            "epoch: 90, val_loss: 0.5722439885139465, val_acc: 0.7894736842105263\n",
            "epoch: 91, train_loss: 0.2128443866968155, train_acc: 0.890625\n",
            "epoch: 91, val_loss: 0.5629916787147522, val_acc: 0.8157894736842105\n",
            "epoch: 91, train_loss: 0.11140243709087372, train_acc: 0.96875\n",
            "epoch: 91, val_loss: 0.6353539228439331, val_acc: 0.8157894736842105\n",
            "epoch: 91, train_loss: 0.4368007183074951, train_acc: 0.8181818181818182\n",
            "epoch: 91, val_loss: 0.5678916573524475, val_acc: 0.8157894736842105\n",
            "epoch: 92, train_loss: 0.20790140330791473, train_acc: 0.921875\n",
            "epoch: 92, val_loss: 0.5355579257011414, val_acc: 0.7894736842105263\n",
            "epoch: 92, train_loss: 0.2192639410495758, train_acc: 0.90625\n",
            "epoch: 92, val_loss: 0.5583688020706177, val_acc: 0.7894736842105263\n",
            "epoch: 92, train_loss: 0.10457605868577957, train_acc: 0.9545454545454546\n",
            "epoch: 92, val_loss: 0.5951655507087708, val_acc: 0.7894736842105263\n",
            "epoch: 93, train_loss: 0.20059064030647278, train_acc: 0.859375\n",
            "epoch: 93, val_loss: 0.6051525473594666, val_acc: 0.8157894736842105\n",
            "epoch: 93, train_loss: 0.20795004069805145, train_acc: 0.90625\n",
            "epoch: 93, val_loss: 0.5772108435630798, val_acc: 0.7631578947368421\n",
            "epoch: 93, train_loss: 0.2321995496749878, train_acc: 0.8636363636363636\n",
            "epoch: 93, val_loss: 0.5055665373802185, val_acc: 0.7894736842105263\n",
            "epoch: 94, train_loss: 0.15405160188674927, train_acc: 0.90625\n",
            "epoch: 94, val_loss: 0.5553547739982605, val_acc: 0.8421052631578947\n",
            "epoch: 94, train_loss: 0.18618690967559814, train_acc: 0.90625\n",
            "epoch: 94, val_loss: 0.6011629700660706, val_acc: 0.8157894736842105\n",
            "epoch: 94, train_loss: 0.05694795399904251, train_acc: 1.0\n",
            "epoch: 94, val_loss: 0.7464891076087952, val_acc: 0.868421052631579\n",
            "epoch: 95, train_loss: 0.2566877603530884, train_acc: 0.90625\n",
            "epoch: 95, val_loss: 0.7256187200546265, val_acc: 0.868421052631579\n",
            "epoch: 95, train_loss: 0.14761982858181, train_acc: 0.9375\n",
            "epoch: 95, val_loss: 0.6201167106628418, val_acc: 0.8157894736842105\n",
            "epoch: 95, train_loss: 0.178410604596138, train_acc: 0.9090909090909091\n",
            "epoch: 95, val_loss: 0.6784400939941406, val_acc: 0.8157894736842105\n",
            "epoch: 96, train_loss: 0.1129356175661087, train_acc: 0.9375\n",
            "epoch: 96, val_loss: 0.655350923538208, val_acc: 0.8157894736842105\n",
            "epoch: 96, train_loss: 0.257976233959198, train_acc: 0.90625\n",
            "epoch: 96, val_loss: 0.5940386056900024, val_acc: 0.8157894736842105\n",
            "epoch: 96, train_loss: 0.6220006942749023, train_acc: 0.7272727272727273\n",
            "epoch: 96, val_loss: 0.6055566072463989, val_acc: 0.868421052631579\n",
            "epoch: 97, train_loss: 0.28314265608787537, train_acc: 0.90625\n",
            "epoch: 97, val_loss: 0.7056282758712769, val_acc: 0.8421052631578947\n",
            "epoch: 97, train_loss: 0.2053481936454773, train_acc: 0.921875\n",
            "epoch: 97, val_loss: 0.6576083898544312, val_acc: 0.8157894736842105\n",
            "epoch: 97, train_loss: 0.2720241844654083, train_acc: 0.8636363636363636\n",
            "epoch: 97, val_loss: 0.6236474514007568, val_acc: 0.8157894736842105\n",
            "epoch: 98, train_loss: 0.2812032997608185, train_acc: 0.875\n",
            "epoch: 98, val_loss: 0.42335695028305054, val_acc: 0.8421052631578947\n",
            "epoch: 98, train_loss: 0.10930760949850082, train_acc: 0.96875\n",
            "epoch: 98, val_loss: 0.523796558380127, val_acc: 0.8421052631578947\n",
            "epoch: 98, train_loss: 0.25556257367134094, train_acc: 0.8636363636363636\n",
            "epoch: 98, val_loss: 0.5658231973648071, val_acc: 0.8157894736842105\n",
            "epoch: 99, train_loss: 0.2642033100128174, train_acc: 0.859375\n",
            "epoch: 99, val_loss: 0.6316321492195129, val_acc: 0.8157894736842105\n",
            "epoch: 99, train_loss: 0.19199848175048828, train_acc: 0.890625\n",
            "epoch: 99, val_loss: 0.6460427045822144, val_acc: 0.8157894736842105\n",
            "epoch: 99, train_loss: 0.33843183517456055, train_acc: 0.8181818181818182\n",
            "epoch: 99, val_loss: 0.6395294666290283, val_acc: 0.7894736842105263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bg9kN18EGYRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Uq9gdq9GYNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TnWbMnH_GYJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YrowuwzuGYE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## graph from networkx"
      ],
      "metadata": {
        "id": "GBDz1XgINGtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tD5CP4-wNAU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YGYDCALiNAR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jcoJ1DIv28Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch geom with Pytorch lightning"
      ],
      "metadata": {
        "id": "dgc78gzyMhgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_benchmark():\n",
        "    tu_dataset = geom_datasets.TUDataset(root='data_MUTAG', name=\"MUTAG\")\n",
        "    torch.manual_seed(42)\n",
        "    tu_dataset.shuffle()\n",
        "    train_dataset = tu_dataset[:150]\n",
        "    test_dataset = tu_dataset[150:]\n",
        "    graph_train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    graph_val_loader = DataLoader(test_dataset, batch_size=64) # Additional loader if you want to change to a larger dataset\n",
        "    graph_test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "    return graph_train_loader, graph_val_loader, graph_test_loader"
      ],
      "metadata": {
        "id": "7NFPTwXPMl1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_train_loader, graph_val_loader, graph_test_loader = get_benchmark()"
      ],
      "metadata": {
        "id": "HVoWW-hYMllP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1df7c6e-e9fe-4d4c-b176-c4e1ef195d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Extracting data_MUTAG/MUTAG/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "logger = TensorBoardLogger('/content/drive/MyDrive/DILI_models/GNN/logs/tb_logs', name=\"my_model\")"
      ],
      "metadata": {
        "id": "LR4n2OBHzdsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Em8uWgtMkSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningGCNClassifier(pl.LightningModule):\n",
        "    def __init__(self, c_in, c_hidden, c_out, dropout_conv=0.1, dropout_linear=0.5, **kwargs):\n",
        "        super().__init__()\n",
        "        # initialize model\n",
        "        # self.model = GCNModelClassifier(c_in, c_hidden, c_out, dropout_conv, dropout_linear)\n",
        "        self.model = GraphConvModelClassifier(c_in, c_hidden, c_out, dropout_conv, dropout_linear)\n",
        "\n",
        "        # initialize matrix\n",
        "        self.accuracy = torchmetrics.Accuracy()\n",
        "        # self.recall = torchmetrics.Recall()\n",
        "        # self.precision = torchmetrics.Precision()\n",
        "\n",
        "    def forward(self, batch):\n",
        "        x, edge_index, batch_index = batch.x, batch.edge_index, batch.batch\n",
        "        x = self.model(x, edge_index, batch_index)\n",
        "        return x\n",
        "\n",
        "    def loss_criterion(self, logits, labels):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        return criterion(logits, labels)\n",
        "        # return F.binary_cross_entropy(logits, labels)\n",
        "\n",
        "    def compute_metrix(self, logits, labels):\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        accuracy = self.accuracy(predictions, labels)\n",
        "        # recall = self.recall(predictions, labels)\n",
        "        # precision = self.precision(predictions, labels)\n",
        "        return accuracy\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        y = batch.y.type(torch.long)\n",
        "        logits = self.forward(batch)\n",
        "        loss = self.loss_criterion(logits, y)\n",
        "        # compute metrix\n",
        "        accuracy = self.compute_metrix(logits, y)\n",
        "        # self.log('train_loss', loss)\n",
        "        # self.log('train_accuracy', accuracy)\n",
        "        # self.log('train_recall', recall)\n",
        "        # self.log('train_precision', precision)\n",
        "\n",
        "        # create logs\n",
        "        logs = {\n",
        "            \"loss\": loss,\n",
        "            'train_accuracy': accuracy\n",
        "            }\n",
        "        \n",
        "        # construct a batch dict for loss and other logged items\n",
        "        batch_dict={\n",
        "            \"loss\": loss,\n",
        "            \"log\": logs,\n",
        "        }\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_index):\n",
        "        y = batch.y.type(torch.long)\n",
        "        logits = self.forward(batch)\n",
        "        val_loss = self.loss_criterion(logits, y)\n",
        "        # compute metrix        \n",
        "        accuracy = self.compute_metrix(logits, y)\n",
        "        # self.log('val_loss', val_loss)\n",
        "        # self.log('val_accuracy', accuracy)\n",
        "        # self.log('val_recall', recall)\n",
        "        # self.log('val_precision', precision)\n",
        "        \n",
        "        # create logs\n",
        "        logs = {\n",
        "            \"val_loss\": val_loss,\n",
        "            'val_accuracy': accuracy\n",
        "            }\n",
        "\n",
        "        batch_dict={\n",
        "            \"val_loss\": val_loss,\n",
        "            \"log\": logs,\n",
        "        }\n",
        "\n",
        "        return batch_dict\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        # outputs = list of dictionaries\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        self.logger.experiment.add_scalar(\"Loss/Val\", avg_loss, self.current_epoch)\n",
        "        \n",
        "        epoch_dictionary={'val_loss': avg_loss}\n",
        "        \n",
        "        return epoch_dictionary\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_index):\n",
        "        y = batch.y.type(torch.long)\n",
        "        logits = self.forward(batch)\n",
        "        # compute metrix\n",
        "        accuracy = self.compute_metrix(logits, y)\n",
        "        self.log('test_accuracy', accuracy)\n",
        "        # self.log('test_recall', recall)\n",
        "        # self.log('test_precision', precision)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-2, weight_decay=0.0)\n",
        "        return optimizer\n",
        "\n"
      ],
      "metadata": {
        "id": "ot5e1P2tMo2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lightning_training(train_dataloader, test_dataloader, dev_dataloader=None):\n",
        "    pl.seed_everything(42)\n",
        "    model = LightningGCNClassifier(c_in=77, c_hidden=256, c_out=2)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=50,\n",
        "        gpus=1,\n",
        "        logger=logger,\n",
        "    )\n",
        "    trainer.fit(model, graph_train_loader, graph_val_loader)\n",
        "    # trainer.fit(model, train_dataloader, test_dataloader)\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "frBp7j0aMozD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(42)\n",
        "model = LightningGCNClassifier(c_in=7, c_hidden=256, c_out=2)\n",
        "# model = LightningGCNClassifier(c_in=77, c_hidden=256, c_out=2)\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=50,\n",
        "    gpus=1,\n",
        "    logger=logger,\n",
        "    # fast_dev_run=True,\n",
        ")\n",
        "trainer.fit(model, graph_train_loader, graph_val_loader)\n",
        "# trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "gK3X2RnjMowa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = trainer.test(model, test_dataloaders=graph_val_loader, verbose=False)"
      ],
      "metadata": {
        "id": "09u_27_PCKBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBgV37Z9CJ6H",
        "outputId": "1d4a5c57-3607-483f-aee1-20ced1bf9605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.6842105388641357}]"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LightningGCNClassifier.log"
      ],
      "metadata": {
        "id": "PR9GZYCUCJzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598af752-8f0b-4890-c991-6dce7c9588ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function pytorch_lightning.core.lightning.LightningModule.log>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls lightning_logs"
      ],
      "metadata": {
        "id": "6cOg_iLbCJuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c18cee-9291-4f2f-ad91-ad8e2cdca115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "version_0  version_1  version_2  version_3  version_4  version_5  version_6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls tb_logs/my_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqjroC-D8AHY",
        "outputId": "61f3224c-5665-424a-f9b6-627ba61bf941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "version_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "FzXirG5pCJo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437e5b0b-6622-4961-c8e4-2cb89ca8b8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/DILI_models/GNN/logs/tb_logs"
      ],
      "metadata": {
        "id": "ZvwtELHGCJku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard import notebook\n",
        "notebook.list() # View open TensorBoard instances"
      ],
      "metadata": {
        "id": "e1v7dMItCJgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab28ec72-0ab3-4e52-fad6-12cb0a910543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Known TensorBoard instances:\n",
            "  - port 6007: logdir lightning_logs (started 0:47:39 ago; pid 683)\n",
            "  - port 6006: logdir lightning_logs/version_1 (started 0:48:17 ago; pid 656)\n",
            "  - port 6010: logdir /content/drive/MyDrive/DILI_models/GNN/logs/tb_logs (started 0:00:04 ago; pid 1266)\n",
            "  - port 6008: logdir lightning_logs/version_2 (started 0:33:01 ago; pid 840)\n",
            "  - port 6009: logdir tb_logs (started 0:09:17 ago; pid 1122)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Control TensorBoard display. If no port is provided, \n",
        "# the most recently launched TensorBoard is used\n",
        "notebook.display(port=6008, height=1000) "
      ],
      "metadata": {
        "id": "s0CQg6mL2Gl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir/Path(\"lightning_logs/version_2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY_IaPWu2GfQ",
        "outputId": "13e236eb-e783-4f24-860b-f0fa7d39811b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/DILI_models/GNN/logs/lightning_logs/version_2')"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/DILI_models/GNN/logs/tb_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEYXco5D2Gap",
        "outputId": "5d48cdfe-800e-4b3f-f90d-bb5fedaab629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r lightning_logs/version_2 /content/drive/MyDrive/DILI_models/GNN/logs/lightning_logs/version_2"
      ],
      "metadata": {
        "id": "Dhp254gk2GO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HR6j2zZ02GLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7e_VygSs2GIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "yW43Z0DH3Ifj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# rdkit"
      ],
      "metadata": {
        "id": "JJv9qxDcNwgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RDkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "p8oaHX0epi1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nodes"
      ],
      "metadata": {
        "id": "IC1F5wLINzwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "u5GbwVdN229V",
        "outputId": "34a278a2-f21b-4ee6-8efb-c0ee55eae96a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7f11796448f0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# read molecule from SMILES\n",
        "m = Chem.MolFromSmiles('[C@H]c1cc(O)ccc1')\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get atoms\n",
        "[atom.GetSymbol() for atom in m.GetAtoms()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdsFAyST-GrE",
        "outputId": "73847653-ded0-414c-886e-2f00a38907c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C', 'C', 'C', 'C', 'O', 'C', 'C', 'C']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get atom by index\n",
        "m.GetAtomWithIdx(0).GetSymbol()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bk6m1GSCBmz_",
        "outputId": "c21b8d43-409a-4cf0-b22d-5db07a80ae67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the neighbors of an atom\n",
        "print([x.GetSymbol() for x in m.GetAtomWithIdx(3).GetNeighbors()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOllstd6C4Kk",
        "outputId": "3d6c0d3b-ae61-4da1-f292-060bb6e52a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C', 'O', 'C']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = m.GetAtomWithIdx(3).GetNeighbors()[-1].GetBonds()[0]\n",
        "print(b.GetBeginAtomIdx(), b.GetEndAtomIdx(), b.GetBondType())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyKV2wGwDcto",
        "outputId": "5c1f1e6e-1b75-4c73-c147-55f5fc43ad0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 5 AROMATIC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### node features"
      ],
      "metadata": {
        "id": "7wXEJ33vI3yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h9qG-y_8Kv7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_one_hot_encoding(query, vocab):\n",
        "    if query not in vocab:\n",
        "        query = vocab[-1] # use 'other' as the last element\n",
        "    one_hot_vec = [int(match_result) for match_result in list(map(lambda item: query == item, vocab))]\n",
        "    return one_hot_vec"
      ],
      "metadata": {
        "id": "5jhWX-SaMU2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adj_mx_to_edge_list(adj_matrix, wide=True):\n",
        "    '''\n",
        "    This takes a 2d array as input, and output an edge list (source, targe) with shape (2, n_edges).\n",
        "    '''\n",
        "    row_idx, col_idx = np.nonzero(adj_matrix)\n",
        "    row_idx = np.array(row_idx)\n",
        "    col_idx = np.array(col_idx)\n",
        "    if wide:\n",
        "        edge_list = np.stack((row_idx, col_idx), axis=0)\n",
        "    else:\n",
        "        edge_list = np.stack((row_idx, col_idx), axis=1)\n",
        "    return edge_list\n",
        "\n",
        "def edge_list_to_adj_mx(edge_list):\n",
        "    '''\n",
        "    This takes a 2d-array edge list (source, targe) as input, and output an adj_matrix.\n",
        "    '''\n",
        "    n_row, n_col = edge_list.shape\n",
        "    # wide\n",
        "    if n_row < n_col:\n",
        "        dim_adj = int(n_col/2)\n",
        "        adj_matrix = np.zeros((dim_adj, dim_adj), dtype=np.int64)\n",
        "        for k in range(n_col):\n",
        "            i = edge_list[0, k]\n",
        "            j = edge_list[1, k]\n",
        "            adj_matrix[i, j] = 1\n",
        "    else: \n",
        "        dim_adj = int(n_row/2)\n",
        "        adj_matrix = np.zeros((dim_adj, dim_adj), dtype=np.int64)\n",
        "        for i, j in edge_list:\n",
        "            adj_matrix[i, j] = 1\n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "71Ft_rM2OpJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "    'atom_type': ['Li', 'Be', 'B', 'C','N','O','F','Na','Mg','Al','Si','P','S','Cl','K','Ca','Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn','Ga','Ge','As','Se','Br','I','Tl','Yb','Sb','Sn','Ag','Pd','Co','Au','Cd','In','Zr','Pt','Hg','Pb','OTHER'],\n",
        "    'hybridization': [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"],\n",
        "    'chirality_type': [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"OTHER\"],\n",
        "    'num_neighbors': [0, 1, 2, 3, 4, \"MoreThanFour\"],\n",
        "    'formal_charge': [-3, -2, -1, 0, 1, 2, 3, \"OTHER\"],\n",
        "    'num_hydrogens': [0, 1, 2, 3, 4, \"MoreThanFour\"],\n",
        "    'bond_type': [\"SINGLE\", \"DOUBLE\", \"TRIPLE\", \"AROMATIC\"],\n",
        "    'stereo_type': [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"],\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "0X2FL1MWOzg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chemical_Graph:\n",
        "    def __init__(self, smiles, label, vocab, chirality=True, hydrogens_implicit=True, stereochemistry=True):\n",
        "        self.molecule = Chem.MolFromSmiles(smiles)\n",
        "        self.label = torch.tensor(np.array([label])).float()\n",
        "        self.vocab = vocab\n",
        "        if not hydrogens_implicit:\n",
        "            self.vocab['atom_type'] = ['H'] + self.vocab['atom_type']\n",
        "        self.chirality = chirality\n",
        "        self.hydrogens_implicit = hydrogens_implicit\n",
        "        self.stereochemistry = stereochemistry\n",
        "        # standard scalers\n",
        "        self.scalers = {\n",
        "            'atomic_mass': None,\n",
        "            'vdw_radius': None,\n",
        "            'covalent_radius': None,\n",
        "        }\n",
        "        self.create_scalers()\n",
        "        # dimensions\n",
        "        self.n_nodes = self.molecule.GetNumAtoms()\n",
        "        self.n_edges = 2*self.molecule.GetNumBonds()\n",
        "        self.n_node_features = len(self.get_atom_features(self.molecule.GetAtomWithIdx(0)))\n",
        "        self.n_egde_features = len(self.get_bond_features(self.molecule.GetBonds()[0]))\n",
        "        # get graph-level data (node/edge features, edge_index, label)\n",
        "        self.get_graph_data()\n",
        "\n",
        "    def train_standard_scaler(self, atom_features):\n",
        "        '''\n",
        "        input should be a 2d array\n",
        "        '''\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(atom_features)\n",
        "        return scaler\n",
        "    \n",
        "    def scaler_transform(self, scaler, data):\n",
        "        scaled_array = scaler.transform(np.array(data).reshape(-1, 1))\n",
        "        return list(scaled_array.reshape(-1))\n",
        "\n",
        "    def create_scalers(self):\n",
        "        atomic_mass = [float(atom.GetMass()) for atom in self.molecule.GetAtoms()]\n",
        "        vdw_radius = [float(Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum())) for atom in self.molecule.GetAtoms()]\n",
        "        covalent_radius = [float(Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum())) for atom in self.molecule.GetAtoms()]\n",
        "        self.scalers['atomic_mass'] = self.train_standard_scaler(atom_features=np.array(atomic_mass).reshape(-1, 1))\n",
        "        self.scalers['vdw_radius'] = self.train_standard_scaler(atom_features=np.array(vdw_radius).reshape(-1, 1))\n",
        "        self.scalers['covalent_radius'] = self.train_standard_scaler(atom_features=np.array(covalent_radius).reshape(-1, 1))\n",
        "\n",
        "    def get_atom_features(self, atom, external_atom_embedding=None):\n",
        "        '''\n",
        "        This generates lists of feature vectors for a given atom, and combines features into a single list of vector. \n",
        "        Output in np.array.\n",
        "        '''\n",
        "        if external_atom_embedding:\n",
        "            atom_type_vec = list(external_atom_embedding)\n",
        "        else:\n",
        "            atom_type_vec = create_one_hot_encoding(str(atom.GetSymbol()), self.vocab['atom_type'])\n",
        "        num_neighbors_vec = create_one_hot_encoding(int(atom.GetDegree()), self.vocab['num_neighbors'])    \n",
        "        formal_charge_vec = create_one_hot_encoding(int(atom.GetFormalCharge()), self.vocab['formal_charge'])    \n",
        "        hybridisation_type_vec = create_one_hot_encoding(str(atom.GetHybridization()), self.vocab['hybridization'])   \n",
        "        is_ring_vec = [int(atom.IsInRing())]    \n",
        "        is_aromatic_vec = [int(atom.GetIsAromatic())]\n",
        "        # use trained scaler to scale selected features\n",
        "        atomic_mass_scaled_vec = self.scaler_transform(self.scalers['atomic_mass'], atom.GetMass())\n",
        "        vdw_radius_scaled_vec = self.scaler_transform(self.scalers['vdw_radius'], Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()))\n",
        "        covalent_radius_scaled_vec = self.scaler_transform(self.scalers['covalent_radius'], Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()))\n",
        "        # combine features vectors into a single list\n",
        "        atom_features_vec = atom_type_vec + num_neighbors_vec + formal_charge_vec + hybridisation_type_vec + is_ring_vec + is_aromatic_vec + atomic_mass_scaled_vec + vdw_radius_scaled_vec + covalent_radius_scaled_vec\n",
        "\n",
        "        if self.chirality:\n",
        "            chirality_type_vec = create_one_hot_encoding(str(atom.GetChiralTag()), self.vocab['chirality_type'])\n",
        "            atom_features_vec += chirality_type_vec\n",
        "    \n",
        "        if not self.hydrogens_implicit:\n",
        "            num_hydrogens_vec = create_one_hot_encoding(int(atom.GetTotalNumHs()), self.vocab['num_hydrogens'])\n",
        "            atom_features_vec += num_hydrogens_vec\n",
        "\n",
        "        return np.array(atom_features_vec)\n",
        "\n",
        "    def get_bond_features(self, bond):\n",
        "        '''\n",
        "        This generates lists of feature vectors for a given bond, and combines features into a single list of vector. \n",
        "        Output in np.array.\n",
        "        '''\n",
        "        bond_type_vec = create_one_hot_encoding(str(bond.GetBondType()), self.vocab['bond_type'])   \n",
        "        bond_is_conjugated_vec = [int(bond.GetIsConjugated())]   \n",
        "        bond_is_ring_vec = [int(bond.IsInRing())]  \n",
        "\n",
        "        bond_features_vec = bond_type_vec + bond_is_conjugated_vec + bond_is_ring_vec\n",
        "    \n",
        "        if self.stereochemistry:\n",
        "            stereo_type_vec = create_one_hot_encoding(str(bond.GetStereo()), self.vocab['stereo_type'])\n",
        "            bond_features_vec += stereo_type_vec\n",
        "        return np.array(bond_features_vec)\n",
        "\n",
        "    def get_graph_data(self):\n",
        "        # node features (X)\n",
        "        X = np.zeros((self.n_nodes, self.n_node_features))\n",
        "        for atom in self.molecule.GetAtoms():\n",
        "            X[atom.GetIdx(), :] = self.get_atom_features(atom)\n",
        "        self.X = torch.tensor(X).float()\n",
        "        # edge index (source, target)\n",
        "        edge_index = adj_mx_to_edge_list(GetAdjacencyMatrix(self.molecule))\n",
        "        self.edge_index = torch.tensor(edge_index).float()\n",
        "        # edge features\n",
        "        edge_features = np.zeros((self.n_edges, self.n_egde_features))\n",
        "        for (bond_idx, (row_idx, col_idx)) in enumerate(self.edge_index):        \n",
        "            edge_features[bond_idx] = self.get_bond_features(self.molecule.GetBondBetweenAtoms(int(row_idx),int(col_idx)))\n",
        "        self.edge_attr = torch.tensor(edge_features).float()\n",
        "\n",
        "    def prepare_pyG_dataset(self):\n",
        "        return Data(x=self.X, edge_index=self.edge_index, edge_attr=self.edge_attr, y=self.label)\n",
        "         "
      ],
      "metadata": {
        "id": "lJpkBbUOfGzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(smiles_codes, labels, vocab):\n",
        "    data_list = []\n",
        "    for smiles_code, label in list(zip(smiles_codes, labels)):\n",
        "        graph = Chemical_Graph(smiles_code, label, vocab)\n",
        "        data_list.append(graph.prepare_pyG_dataset())\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "ccWfc0o2R94G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = Chemical_Graph('[C@H]c1cc(O)ccc1', 1, vocab)"
      ],
      "metadata": {
        "id": "hGWJoymYoQuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# atom type\n",
        "atom_list = ['C','N','O','S','F']\n",
        "[int(match_result) for match_result in list(map(lambda s: 'C' == s, atom_list))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flq9V_CgE19L",
        "outputId": "7f067552-781e-4e76-c3b8-8a0056d4ac0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_neighbors\n",
        "m.GetAtomWithIdx(3).GetDegree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqX0Rt6vKp7x",
        "outputId": "c76b2203-b0af-41b7-a839-906f62a93747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_bonds\n",
        "m.GetAtomWithIdx(3).GetBonds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-dMGQt_Kpbx",
        "outputId": "f2179e74-5dbd-47c7-e32d-7a66df1b0955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<rdkit.Chem.rdchem.Bond at 0x7fadf8e6bbc0>,\n",
              " <rdkit.Chem.rdchem.Bond at 0x7fadf8d93bc0>,\n",
              " <rdkit.Chem.rdchem.Bond at 0x7fadf8d93d50>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# formal charge\n",
        "m.GetAtomWithIdx(4).GetFormalCharge()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoQ2AqFzE158",
        "outputId": "749f1986-249e-4c1d-ef62-f979b2186794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hybridization\n",
        "str(m.GetAtomWithIdx(4).GetHybridization())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "62FMsm1sXhUs",
        "outputId": "cba5d897-642b-4436-8872-bb729013e683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SP2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_hydrogen\n",
        "m.GetAtomWithIdx(4).GetTotalNumHs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmnZNqAPXhOC",
        "outputId": "77b679e0-a5a2-4af6-ea03-981b5f71b379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Van der Watt radius\n",
        "float((Chem.GetPeriodicTable().GetRvdw(m.GetAtomWithIdx(4).GetAtomicNum())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvXZ_9fiE12s",
        "outputId": "dd108790-4c1f-4e2c-bf7b-aac38c9fb736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.55"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bonds"
      ],
      "metadata": {
        "id": "U7ejCReHEvod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get bonds\n",
        "[(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx(), str(bond.GetBondType())) for bond in m.GetBonds()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4hayU--ARbN",
        "outputId": "3d10f656-6de2-4fa9-e6c9-7597c99c7329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1, 'SINGLE'),\n",
              " (1, 2, 'AROMATIC'),\n",
              " (2, 3, 'AROMATIC'),\n",
              " (3, 4, 'SINGLE'),\n",
              " (3, 5, 'AROMATIC'),\n",
              " (5, 6, 'AROMATIC'),\n",
              " (6, 7, 'AROMATIC'),\n",
              " (7, 1, 'AROMATIC')]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.GetBonds()[0].GetBondType()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhUQsGUAE0jB",
        "outputId": "24806c5d-7d0b-4a08-c708-50b1504a502e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rdkit.Chem.rdchem.BondType.SINGLE"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### adjacency matrix"
      ],
      "metadata": {
        "id": "xwt6rmYf9i_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "uDOxJMFR94gx",
        "outputId": "7fe44876-f73f-4206-ab72-39045d8d4437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7fadf8e0b490>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj = GetAdjacencyMatrix(m)\n",
        "print(adj.shape)\n",
        "print(f\"adj_matrix:\\n {adj}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImueHQLEE0f4",
        "outputId": "dd56e291-a998-4738-f9b9-66aa920f2e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8)\n",
            "adj_matrix:\n",
            " [[0 1 0 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 1]\n",
            " [0 1 0 1 0 0 0 0]\n",
            " [0 0 1 0 1 1 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 1]\n",
            " [0 1 0 0 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_idx, col_idx = np.nonzero(adj)\n",
        "print(row_idx)\n",
        "print(col_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFardnYME0co",
        "outputId": "bfc42a77-e9eb-48e6-8903-09023a7214ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 1 2 2 3 3 3 4 5 5 6 6 7 7]\n",
            "[1 0 2 7 1 3 2 4 5 3 3 6 5 7 1 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.stack((np.array(row_idx), np.array(col_idx)), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY7QOfQ9LTom",
        "outputId": "ee09be26-ba2e-4dfa-e95d-c7994ae7898a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [1, 2],\n",
              "       [1, 7],\n",
              "       [2, 1],\n",
              "       [2, 3],\n",
              "       [3, 2],\n",
              "       [3, 4],\n",
              "       [3, 5],\n",
              "       [4, 3],\n",
              "       [5, 3],\n",
              "       [5, 6],\n",
              "       [6, 5],\n",
              "       [6, 7],\n",
              "       [7, 1],\n",
              "       [7, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([[r, c] for r, c in zip(row_idx, col_idx)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ls0Ll2oB5PW",
        "outputId": "db5d3206-7876-4cab-f87e-867382677153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [1, 2],\n",
              "       [1, 7],\n",
              "       [2, 1],\n",
              "       [2, 3],\n",
              "       [3, 2],\n",
              "       [3, 4],\n",
              "       [3, 5],\n",
              "       [4, 3],\n",
              "       [5, 3],\n",
              "       [5, 6],\n",
              "       [6, 5],\n",
              "       [6, 7],\n",
              "       [7, 1],\n",
              "       [7, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(np.array([[r, c] for r, c in zip(row_idx, col_idx)])).float().size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40MHMUJHAwIF",
        "outputId": "f4a276cc-7604-4eaf-88ab-493edd354d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([[r, c] for r, c in zip(row_idx, col_idx)]).reshape(2, 16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4s-ngU5AFgQ",
        "outputId": "d4c9f461-3694-4559-c84e-ad19d44f8b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 0, 1, 2, 1, 7, 2, 1, 2, 3, 3, 2, 3, 4],\n",
              "       [3, 5, 4, 3, 5, 3, 5, 6, 6, 5, 6, 7, 7, 1, 7, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list = adj_mx_to_edge_list(adj)\n",
        "edge_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we9LPvBoE0Zm",
        "outputId": "58cf512b-7cbf-484c-bcfb-5280fa9b9cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 6, 6, 7, 7],\n",
              "       [1, 0, 2, 7, 1, 3, 2, 4, 5, 3, 3, 6, 5, 7, 1, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list_to_adj_mx(edge_list) == adj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcyxBw-VONYP",
        "outputId": "3c6212f1-c413-4df6-8925-6c138e32b0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list = adj_mx_to_edge_list(adj, False)\n",
        "edge_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3oXYShRE0Wh",
        "outputId": "db587eb4-ccad-4570-af9d-f893c79473bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [1, 2],\n",
              "       [1, 7],\n",
              "       [2, 1],\n",
              "       [2, 3],\n",
              "       [3, 2],\n",
              "       [3, 4],\n",
              "       [3, 5],\n",
              "       [4, 3],\n",
              "       [5, 3],\n",
              "       [5, 6],\n",
              "       [6, 5],\n",
              "       [6, 7],\n",
              "       [7, 1],\n",
              "       [7, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list_to_adj_mx(edge_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBekUoVUCuRl",
        "outputId": "53d74c02-141f-482f-e2ed-7c2d81aa8ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 1, 0, 0, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 1, 1, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list_to_adj_mx(edge_list) == adj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWAX_ngZCuLG",
        "outputId": "7c0e35df-c74c-4b84-b753-274d1625c5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r0of8ipaCuHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fB3IgvyACuEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QV2uYnY8CuAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aDt_SZFuBZho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}